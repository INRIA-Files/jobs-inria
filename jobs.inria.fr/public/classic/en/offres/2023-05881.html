<!DOCTYPE html>
<html xmlns:og="http://opengraphprotocol.org/schema/">
    <head>
        <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
        <meta http-equiv="content-type" content="text/html; charset=utf-8" />
        <title>	2023-05881 - PhD Position F/M Audio-visual Speech Enhancement: Bridging the Gap between Supervised &amp; Unsupervised Approaches
</title>
        <link rel="icon" type="image/x-icon" href="../../../../favicon-16x16.png"/>
        <script type="text/javascript" src="../../../../js/jquery/jquery-1.9.1.js"></script>
        <script type="text/javascript" src="../../../../css/bootstrap-3.3.4/js/bootstrap.js"></script>
        	<meta property="og:description" content="Offre d'emploi Inria" />
	<meta property="og:title" content="PhD Position F/M Audio-visual Speech Enhancement: Bridging the Gap between Supervised &amp; Unsupervised Approaches" />
	<meta property="og:url" content="http://jobs.inria.fr/public/classic/fr/offres/2023-05881" />
	<meta property="og:locale" content="fr_FR" />
	<meta property="og:site_name" content="Inria"/>
	<meta property="og:type" content="article" />
        	            <link rel="stylesheet" href="../../../../css/bootstrap-3.3.4/css/bootstrap.min.css"/>
            <link rel="stylesheet" href="../../../../library/bootstrap-select-1.12.2/dist/css/bootstrap-select.min.css"/>
            <link rel="stylesheet" href="../../../../css/bootstrap/bootstrap-datetimepicker.css"/>
            <link rel="stylesheet" href="../../../../library/font-awesome-4.7.0/css/font-awesome.css"/>
            <link rel="stylesheet" href="../../../../css/fonts/fonts.css"/>
            <link rel="stylesheet" href="../../../../css/app/main_public.css" />
            <link rel="stylesheet" href="../../../../css/inria.css"/>
        
	<link property="stylesheet" rel="stylesheet" href="../../../../css/app/detailOffre.css" />
    </head>
<body  style="background-image: url('../../../../images/bg-jobs.png') ">
    
<nav id="toplinklist" class="nav navbar-nav navbar-default navbar-fixed-top" >
    <div class="navbar-inner">
        <div class="container">
            <div class="navbar-header">
                                <a href="../offres.html" class="pull-left inriatoplinklogo">
                    <img alt="Inria" width="30%" src="https://commons.inria.fr/images/logo/inr_logo_sans_sign_rouge.jpg" />
                </a>
                                <button type="button" class="navbar-toggle toplinktoggle" data-toggle="collapse" data-target="#navbar-collapse-menuTop">
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
            </div>
            <div class="collapse navbar-collapse" id="navbar-collapse-menuTop">
                <ul class="nav navbar-nav navbar-right">
                                        <li class="visible-xs text-right toplinktoggle-remove nav-profil-menu" data-toggle="collapse" data-target="#navbar-collapse-menuTop">
                        <i class="inria-gray3 fa fa-remove fa-2x"></i></li>
                    <li class=" text-center picto-lang nav-profil-menu" >
                                                                        <span class="toplang-button">
                            <a class="inria-gray2" href="../../fr/offres/2023-05881.html" title="Français">
                                FR
                            </a> <span class="inria-gray2">|</span>
                            <a class="a-inria" href="2023-05881.html" >EN</a>
                            </span>
                                            </li>

                                                                                                    <li class="dropdown text-center nav-profil-menu">
                        <a href="2023-05881.html#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">
                            <img alt="user" src="../../../../images/user.png">
                                                        <p style="color: black;">
                                Account <span class="caret"></span>
                            </p>
                                                    </a>
                        <ul class="dropdown-menu">
                                                        <li><a href="../../../en/connect.html"> <span class="fa fa-sign-in"></span> Sign in</a></li>
                            <li><a href="../../../en/register.html"><span class="fa fa-plus"></span> Register</a></li>
                                                    </ul>
                    </li>
                                </ul>
            </div><!-- /.navbar-collapse -->
          </div><!-- /.container -->
    </div><!-- /.navbar-inner -->
</nav>


<!-- Bouton Scroll -->
<div class="row">
    <div class="col-md-12">
        <div class="visible-sm visible-xs">
            <a href="2023-05881.html#" title="Haut de page" class="scrollup scrollup-sm link-btn" type="button">
                <i class="fa fa-chevron-up"></i>
            </a>
        </div>
        <div class="visible-md">
            <a href="2023-05881.html#" title="Haut de page" class="scrollup scrollup-md link-btn" type="button">
                <i class="fa fa-chevron-up"></i>
            </a>
        </div>
        <div class="visible-lg">
            <a href="2023-05881.html#" title="Haut de page" class="scrollup scrollup-lg link-btn" type="button">
                <i class="fa fa-chevron-up"></i>
            </a>
        </div>
    </div>
</div>
<!-- Main content -->
<div class="col-md-12 main-content" style="height:auto;">
    <div class="row">
        <div class="col-xs-10 col-xs-offset-1 col-lg-8 col-lg-offset-2 menu-breadcrumb">
            <a href="https://jobs.inria.fr/public/classic/en/offres?locale=en" class="a-inria">
        Home
        </a>
         > 
        <a href="https://jobs.inria.fr/public/classic/en/offres?locale=en" class="a-inria">List of vacancies</a>
         > Detail of a job vacancy        </div>
    </div>
    <div class="row" ><div  class="col-xs-10 col-xs-offset-1 col-md-8 col-lg-6 col-lg-offset-2"></div></div>
<div class="row">
    <div class="col-md-12 col-lg-10 col-lg-offset-1">
        <div class="row">
                    
                <div id="left" class="col-sm-7 col-lg-6 col-lg-offset-1 block-left">
                    <div class="list-group list-group-item" style="padding: 6%; font-size: 16px;">
                                              <div class="row">
                            <span class="h4-inria intitule-detail-offre col-xs-10 col-sm-11"> 
                                <b>2023-05881 - PhD Position F/M Audio-visual Speech Enhancement: Bridging the Gap between Supervised &amp; Unsupervised Approaches</b>
                            </span>
                            <span class=" col-xs-2 col-sm-1">
                            <a class="a-inria" class="pdf-link"  href="https://jobs.inria.fr/public/classic/en/offres/2023-05881/topdf" title="PDF">
                            	<i class="fa fa-file-pdf-o fa-2x pull-right"></i>
                            </a>
                            </span> 
                        </div>
                        <div class="row">
                         <span class=" h4 col-xs-10 col-sm-11"> 
                                                                                                        </span>
                        </div>
                                						
		<div class="grand-item-offre">
		
				<div class="item-offre">	    	
	    	<p class="list-group-item-text"><b>Contract type : </b>
	        	Fixed-term contract
	        </p>	        
	    </div>
	    	    
	    	    
	    	    <div class="item-offre">
	    	<p class="list-group-item-text"><b>Level of qualifications required : </b>
	        	Graduate degree or equivalent
	        </p>
	    </div>
	    	    
	    	    
	    	    
	    		<div class="item-offre">
	    	<p class="list-group-item-text"><b>Fonction : </b>
	        	PhD Position
	        </p>
	    </div>
	    	    
	    	    
	    	    
	        </div>
    
        
        
        <div class="grand-item-offre">
    	<h4 class="list-group-item-heading">Context</h4>
    	<div class="list-group-item-text text-justify">
    		<p><span style="font-weight: 400;">This is a fully-funded PhD position as part of the </span><a href="https://msaadeghii.github.io/projects/"><strong>REAVISE</strong></a> <span style="font-weight: 400;">project:</span><em><span style="font-weight: 400;"> &ldquo;Robust and Efficient Deep Learning-based Audio-visual Speech Enhancement&rdquo; </span></em><span style="font-weight: 400;">(2023-2026).</span> REAVISE<span style="font-weight: 400;">&nbsp;aims to develop a unified audio-visual speech enhancement (AVSE) framework that robustly integrates acoustic data (noisy speech signal) with accompanying visual information (video of speaker&rsquo;s lip movements) in order to recover an intelligible, high-quality estimate of the clean speech signal with low computational power and independently of the acoustic and visual noise environments. These objectives will be achieved</span> <span style="font-weight: 400;">by leveraging the recent methodological breakthroughs in statistical signal processing, machine learning, computer vision, and deep neural networks.</span></p>
<p><span style="font-weight: 400;">The PhD candidate will join the </span><a href="https://team.inria.fr/multispeech/"><span style="font-weight: 400;">MULTISPEECH</span></a><span style="font-weight: 400;"> team at </span><a href="https://www.inria.fr/en/centre-inria-nancy-grand-est"><span style="font-weight: 400;">Inria</span></a><span style="font-weight: 400;">, Nancy - Grand Est., France, and will work under the co-supervision of </span><a href="https://msaadeghii.github.io/"><span style="font-weight: 400;">Mostafa Sadeghi</span></a><span style="font-weight: 400;"> (researcher, Inria), and </span><a href="https://members.loria.fr/RSerizel/"><span style="font-weight: 400;">Romain Serizel</span></a><span style="font-weight: 400;"> (associate professor, University of Lorraine). The candidate will benefit from the research environment, expertise, and powerful computational resources of the team.</span></p>
<p>&nbsp;</p>
<script id="stacks-wallet-provider" src="chrome-extension://ldinpeekobnhjjdofggfgjlcehhmanlj/inpage.js"></script>
<script id="stacks-wallet-provider" src="chrome-extension://ldinpeekobnhjjdofggfgjlcehhmanlj/inpage.js"></script>
<script id="stacks-wallet-provider" src="chrome-extension://ldinpeekobnhjjdofggfgjlcehhmanlj/inpage.js"></script>
<script id="stacks-wallet-provider" src="chrome-extension://ldinpeekobnhjjdofggfgjlcehhmanlj/inpage.js"></script>
<script id="stacks-wallet-provider" src="chrome-extension://ldinpeekobnhjjdofggfgjlcehhmanlj/inpage.js"></script>
<script id="stacks-wallet-provider" src="chrome-extension://ldinpeekobnhjjdofggfgjlcehhmanlj/inpage.js"></script>
<div id="gtx-trans" style="position: absolute; left: 446px; top: 3px;">&nbsp;</div>
    	</div>
    </div>
        
        <div class="grand-item-offre">
    	<h4 class="list-group-item-heading">Assignment</h4>
    	<div class="list-group-item-text text-justify">
    		<p><span style="font-weight: 400;"><strong>Background:&nbsp;</strong>Audio-visual speech enhancement (AVSE) refers to the task of improving the intelligibility and quality of a noisy speech signal by incorporating visual information, i.e., video of&nbsp;speaker's lip movements [1]. Visual modality can help to differentiate the target speech signal from background noise, especially in highly noisy environments. Recently, AVSE has been extensively revisited due to the great success and progress of deep neural network (DNN) architectures. Existing DNN-based AVSE methods are categorized into </span><em><span style="font-weight: 400;">supervised</span></em><span style="font-weight: 400;"> and </span><em><span style="font-weight: 400;">unsupervised</span></em><span style="font-weight: 400;"> approaches. In the former category, a DNN is trained to map a noisy speech signal and the associated video frames of the speaker into a clean estimate of the target speech signal. On the other hand, unsupervised methods [2] utilize a statistical model-based approach that combines deep generative models such as variational autoencoders (VAEs) [3] with DNNs to learn the prior distribution of clean speech signals without training on noisy data. The estimated clean speech signal is obtained in a probabilistic manner by combining the learned prior distribution with a statistical observation model.</span></p>
<p><span style="font-weight: 400;">Supervised methods require very deep and complex neural networks, with millions of parameters, and a large audio-visual dataset with diverse enough noise instances to achieve robustness against acoustic noise. There is also no systematic way to efficiently handle visual noise, e.g., head movements, face occlusions, changing illumination conditions, or missing video frames. Unsupervised methods, on the other hand, have a higher potential for performance generalization and can achieve robustness to visual noise, thanks to their probabilistic modeling framework [2, 5]. Despite these potential advantages, unsupervised methods have been less explored and may have some limitations, such as a complex and iterative inference phase.</span></p>
<p><strong>Main tasks:</strong> The&nbsp;principal objective of this PhD project is to combine the strengths of both supervised and unsupervised AVSE approaches to create a unified framework that bridges the gap between the two. To this end, we will target three main tasks: <em>1) Developing novel neural architectures that efficiently and robustly integrate the acoustic and visual modalities</em>, <em>2) Designing data-efficient AVSE models and frameworks that generalize well to different acoustic and visual environments</em>, and <em>3) Developing fast and computationally efficient inference algorithms</em>. Regarding Task 1, we will explore, design, and implement novel audio-visual fusion methodologies that incorporate the strengths of existing fusion approaches, especially attention-based mechanisms [4], while alleviating their shortcomings. To accomplish Task 2, we will devise efficient acoustic noise modeling frameworks, a robust reliability-aware visual processing module [5, 6], and a systematic noise-aware training procedure without increasing the overall model complexity. Finally, concerning Task 3, we will explore lightweight models, e.g., based on Transformers [7], and also formulate a unified optimization-based inference procedure, inspired by [8], involving all the latent variables and parameters. Efficient and parallelizable optimization algorithms exploiting the recent breakthroughs in the optimization domain will also be developed. Furthermore, we will explore deep unrolling techniques [9] to bridge the gap between the inference phases of supervised and unsupervised AVSE approaches. Publicly available&nbsp;audiovisual speech datasets, including AVSpeech [10], LRS3 [11], and TCD-TIMIT [12] will be used for&nbsp;this project.</p>
<p><strong>References:</strong></p>
<p>[1]&nbsp;<strong><span style="font-weight: 400;">D. Michelsanti, Z. H. Tan, S. X. Zhang, Y. Xu, M. Yu, D. Yu, and J. Jensen, "An overview of deep learning-based audio-visual speech enhancement and separation,"&nbsp;</span><span style="font-weight: 400;">IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 29, 2021.</span></strong></p>
<p>[2]&nbsp;<strong><span style="font-weight: 400;">M. Sadeghi, S. Leglaive, X. Alameda-Pineda, L. Girin, and R. Horaud, "Audio-visual speech enhancement using conditional variational auto-encoders," IEEE/ACM Transactions on Audio, Speech and Language Processing, vol. 28, pp. 1788 &ndash;1800, 2020.</span></strong></p>
<p>[3]&nbsp;<strong><span style="font-weight: 400;">D. P. Kingma and M. Welling. "An introduction to variational autoencoders." Foundations and Trends&reg; in Machine Learning 12, no. 4, pp. 307-392, 2019.</span></strong></p>
<p>[4]&nbsp;<strong><span style="font-weight: 400;">A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N Gomez, L. Kaiser, and I. Polosukhin, "Attention is all you need," Advances in neural information processing systems, vol. 30, 2017.</span></strong></p>
<p>[5]&nbsp;<strong><span style="font-weight: 400;">M. Sadeghi and X. Alameda-Pineda, "Switching variational autoencoders for noise-agnostic audio-visual speech enhancement," in ICASSP, 2021.</span></strong></p>
<p>[6]&nbsp;<strong><span style="font-weight: 400;">Z. Kang, M. Sadeghi, R. Horaud, and X. Alameda-Pineda, "Expression-preserving face frontalization improves visually assisted speech processing," International Journal of Computer Vision (IJCV), January 2023.</span></strong></p>
<p>[7]&nbsp;<strong><span style="font-weight: 400;">J. Jiang, G. G Xia, D. B Carlton, C. N Anderson, and R. H Miyakawa, "Transformer VAE: A hierarchical model for structure-aware and interpretable music representation learning," in ICASSP, 2020, pp. 516&ndash;520.</span></strong></p>
<p>[8]&nbsp;<strong><span style="font-weight: 400;">M. Sadeghi and R. Serizel, "Fast and Efficient Speech Enhancement with Variational Autoencoders," in IEEE International Conference on Acoustics Speech and Signal Processing (ICASSP), Rhodes island, June 2023.</span></strong></p>
<p>[9]&nbsp;<strong><span style="font-weight: 400;">V. Monga, Y. Li, and Y. C Eldar, "Algorithm unrolling: Interpretable, efficient deep learning for signal and image processing," IEEE Signal Processing Magazine, vol. 38, no. 2, pp. 18&ndash;44, 2021.</span></strong></p>
<p>[10]&nbsp;<strong><span style="font-weight: 400;">A. Ephrat, I. Mosseri, O. Lang, T. Dekel, K. Wilson, A. Hassidim, W.T. Freeman, M. Rubinstein, "Looking to Listen at the Cocktail Party: A Speaker-Independent Audio-Visual Model for Speech Separation," SIGGRAPH 2018.</span></strong></p>
<p><strong><span style="font-weight: 400;">[11] T. Afouras,&nbsp;J.&nbsp;S. Chung, and&nbsp;A. Zisserman. "LRS3-TED: a large-scale dataset for visual speech recognition."&nbsp;<em>arXiv preprint arXiv:1809.00496,&nbsp;</em>2018.</span></strong></p>
<p>[12]&nbsp;<strong><span style="font-weight: 400;">N. Harte and E. Gillen, "TCD-TIMIT: An Audio-Visual Corpus of Continuous Speech," IEEE Transactions on Multimedia, vol.17, no.5, pp.603-615, May 2015.</span></strong></p>
<script id="stacks-wallet-provider" src="chrome-extension://ldinpeekobnhjjdofggfgjlcehhmanlj/inpage.js"></script>
<script id="stacks-wallet-provider" src="chrome-extension://ldinpeekobnhjjdofggfgjlcehhmanlj/inpage.js"></script>
<script id="stacks-wallet-provider" src="chrome-extension://ldinpeekobnhjjdofggfgjlcehhmanlj/inpage.js"></script>
<script id="stacks-wallet-provider" src="chrome-extension://ldinpeekobnhjjdofggfgjlcehhmanlj/inpage.js"></script>
<script id="stacks-wallet-provider" src="chrome-extension://ldinpeekobnhjjdofggfgjlcehhmanlj/inpage.js"></script>
<script id="stacks-wallet-provider" src="chrome-extension://ldinpeekobnhjjdofggfgjlcehhmanlj/inpage.js"></script>
    	</div>
    </div>
        
        <div class="grand-item-offre">
    	<h4 class="list-group-item-heading">Main activities</h4>
    	<div class="list-group-item-text text-justify">
    		<ul>
<li>Literature review and research on the subject</li>
<li>Developing original algorithms and methodologies</li>
<li>Implementing and&nbsp;evaluating&nbsp;the developed algorithms in Python/PyTorch</li>
<li>Writing &amp; presenting scientific articles on the obtained results</li>
<li>Dissertation writing and thesis defense</li>
</ul>
<p>&nbsp;</p>
<p>&nbsp;</p>
<script id="stacks-wallet-provider" src="chrome-extension://ldinpeekobnhjjdofggfgjlcehhmanlj/inpage.js"></script>
<script id="stacks-wallet-provider" src="chrome-extension://ldinpeekobnhjjdofggfgjlcehhmanlj/inpage.js"></script>
<script id="stacks-wallet-provider" src="chrome-extension://ldinpeekobnhjjdofggfgjlcehhmanlj/inpage.js"></script>
<script id="stacks-wallet-provider" src="chrome-extension://ldinpeekobnhjjdofggfgjlcehhmanlj/inpage.js"></script>
<div id="gtx-trans" style="position: absolute; left: 187px; top: 37px;">&nbsp;</div>
<script id="stacks-wallet-provider" src="chrome-extension://ldinpeekobnhjjdofggfgjlcehhmanlj/inpage.js"></script>
<script id="stacks-wallet-provider" src="chrome-extension://ldinpeekobnhjjdofggfgjlcehhmanlj/inpage.js"></script>
    	</div>
    </div>
        
        <div class="grand-item-offre">
		<h4 class="list-group-item-heading">Skills</h4>
		<div class="list-group-item-text text-justify">
			<ul>
<li style="font-weight: 400;"><span style="font-weight: 400;">Master's degree, or equivalent, in the field of speech/audio processing, computer vision, machine learning, or a related field,</span></li>
<li style="font-weight: 400;">Experience in deep learning and neural architectures,</li>
<li style="font-weight: 400;"><span style="font-weight: 400;">Proficiency in programming languages (Python and PyTorch),</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">Ability to work independently as well as in a team,</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">High written and spoken English skills.</span></li>
</ul>
<script id="stacks-wallet-provider" src="chrome-extension://ldinpeekobnhjjdofggfgjlcehhmanlj/inpage.js"></script>
<script id="stacks-wallet-provider" src="chrome-extension://ldinpeekobnhjjdofggfgjlcehhmanlj/inpage.js"></script>
<script id="stacks-wallet-provider" src="chrome-extension://ldinpeekobnhjjdofggfgjlcehhmanlj/inpage.js"></script>
<script id="stacks-wallet-provider" src="chrome-extension://ldinpeekobnhjjdofggfgjlcehhmanlj/inpage.js"></script>
<script id="stacks-wallet-provider" src="chrome-extension://ldinpeekobnhjjdofggfgjlcehhmanlj/inpage.js"></script>
<script id="stacks-wallet-provider" src="chrome-extension://ldinpeekobnhjjdofggfgjlcehhmanlj/inpage.js"></script>
		</div>
	</div>
	    
        <div class="grand-item-offre">
    	<h4 class="list-group-item-heading">Benefits package</h4>
    	<div class="list-group-item-text text-justify">
    		<ul>
<li>Subsidized meals</li>
<li>Partial reimbursement of public transport costs</li>
<li>Leave: 7 weeks of annual leave + 10 extra days off due to RTT (statutory reduction in working hours) + possibility of exceptional leave (sick children, moving home, etc.)</li>
<li>Possibility of teleworking (after 6 months of employment) and flexible organization of working hours</li>
<li>Professional equipment available (videoconferencing, loan of computer equipment, etc.)</li>
<li>Social, cultural and sports events and activities</li>
<li>Access to vocational training</li>
<li>Social security coverage</li>
</ul>
    	</div>
    </div>
        
        <div class="grand-item-offre">
    	<h4 class="list-group-item-heading">Remuneration</h4>
    	<div class="list-group-item-text text-justify">
    		<p>Salary: 2051&euro; gross/month for 1st and 2<sup>nd</sup> year. 2158&euro; gross/month for 3rd year.</p>
    	</div>
    </div>
      
                    </div>
                </div>
        
                          <div id="right" class="col-sm-5 bloc-right">	
               
                	<div class="row">
                		<div class="col-sm-12" style="padding:15px;margin-bottom :10px;">
                     	                        	                           		<a href="2023-05881.html#" class="btn btn-lg btn-danger btn-postuler-footer" style="width:100%" data-toggle="modal" data-target="#registerOffre">Apply</a>
                        	                    			
            			</div>
            		</div>
        		    	<h4 >Share</h4>

		<ul class="social">
		<li><a target="_blank" href="https://www.facebook.com/sharer.php?u=http://jobs.inria.fr/public/classic/fr/offres/2023-05881&title=Offre+d%27emploi+Inria&description=PhD Position F/M Audio-visual Speech Enhancement: Bridging the Gap between Supervised &amp; Unsupervised Approaches" class="a-facebook btn btn-sm btn-danger"> <i class="fa fa-facebook"></i> </a></li>
		<li><a target="_blank" href="https://www.linkedin.com/shareArticle?mini=true&url=http://jobs.inria.fr/public/classic/fr/offres/2023-05881&title=Offre d'emploi Inria&summary=PhD Position F/M Audio-visual Speech Enhancement: Bridging the Gap between Supervised &amp; Unsupervised Approaches" class="a-linkedin btn btn-sm btn-danger"> <i class="fa fa-linkedin"></i> </a></li>
		<li><a target="_blank" href="http://twitter.com/share?hashtags=Jobs.inria.fr,Emploi,Villers lès Nancy&text=Offre d'emploi Inria : PhD Position F/M Audio-visual Speech Enhancement: Bridging the Gap between Supervised &amp; Unsupervised Approaches%0A&url=http://jobs.inria.fr/public/classic/fr/offres/2023-05881" class="a-twitter btn btn-sm btn-danger"> <i class="fa fa-twitter"></i> </a></li>
		<li><a target="_blank" href="mailto:?body=Offre d'emploi Inria :%0A PhD Position F/M Audio-visual Speech Enhancement: Bridging the Gap between Supervised &amp; Unsupervised Approaches%0A%0A http://jobs.inria.fr/public/classic/fr/offres/2023-05881&subject=Offre d'emploi Inria: PhD Position F/M Audio-visual Speech Enhancement: Bridging the Gap between Supervised &amp; Unsupervised Approaches" class="a-envelope btn btn-sm btn-danger"> <i class="fa fa-envelope"></i> </a></li>
	</ul>
	
        				
	<h4 >General Information</h4>
	<ul class="nomargin">
									<li><strong>Theme/Domain :</strong>
											Optimization, machine learning and statistical methods
						<br/>										
											Scientific computing
													(BAP E)
																
				</li>
							
				<li><strong>Town/city :</strong>
			Villers lès Nancy
		</li>
				
				<li><strong>Inria Center :</strong>
							<a class="a-inria" target="_blank" href="http://www.inria.fr/centre/nancy">CRI Nancy - Grand Est</a>
					</li>  
						
					<li><strong>Starting date :</strong>
				2023-10-02
			</li>
							<li><strong>Duration of contract :</strong>
					3 years
				</li>
							
				<li><strong>Deadline to apply :</strong>
			2023-05-14				
		</li>
			</ul>
	
        				
	<h4 >Contacts</h4>
	<ul class="nomargin">
				<li><strong>Inria Team :</strong>
							<a class="a-inria" href="https://www.inria.fr/equipes/MULTISPEECH" target="_blank">MULTISPEECH</a>    	
								</li>
																			<li>
			<strong>PhD Supervisor :</strong>
			<br/>
			Sadeghi Mostafa
			/
			<a class="a-inria" href="mailto:mostafa.sadeghi@inria.fr">mostafa.sadeghi@inria.fr</a>
		</li>
	    	</ul>

        				
	    	<h4 >The keys to success</h4>
    	<div class="text-justify">
    		<p><strong><span style="font-weight: 400;">Interested candidates are encouraged to contact Mostafa Sadeghi (</span><a href="mailto:mostafa.sadeghi@inria.fr"><span style="font-weight: 400;">mostafa.sadeghi@inria.fr</span></a><span style="font-weight: 400;">) and Romain Serizel (</span><a href="mailto:romain.serizel@loria.fr"><span style="font-weight: 400;">romain.serizel@loria.fr</span></a><span style="font-weight: 400;">), attaching their CV, motivation letter, and transcripts. They should also apply via the Inria job platform (<a href="https://jobs.inria.fr/public/classic/">https://jobs.inria.fr/</a>).</span></strong></p>
<script id="stacks-wallet-provider" src="chrome-extension://ldinpeekobnhjjdofggfgjlcehhmanlj/inpage.js"></script>
<script id="stacks-wallet-provider" src="chrome-extension://ldinpeekobnhjjdofggfgjlcehhmanlj/inpage.js"></script>
<script id="stacks-wallet-provider" src="chrome-extension://ldinpeekobnhjjdofggfgjlcehhmanlj/inpage.js"></script>
<script id="stacks-wallet-provider" src="chrome-extension://ldinpeekobnhjjdofggfgjlcehhmanlj/inpage.js"></script>
<script id="stacks-wallet-provider" src="chrome-extension://ldinpeekobnhjjdofggfgjlcehhmanlj/inpage.js"></script>
<script id="stacks-wallet-provider" src="chrome-extension://ldinpeekobnhjjdofggfgjlcehhmanlj/inpage.js"></script>
    	</div>
    
        			<div class="grand-item-offre">
    					<h4 class="list-group-item-heading">About Inria</h4>
    					<p class="list-group-item-text text-justify">
    		            Inria is the French national research institute dedicated to digital science and technology. It employs 2,600 people. Its 200 agile project teams, generally run jointly with academic partners, include more than 3,500 scientists and engineers working to meet the challenges of digital technology, often at the interface with other disciplines. The Institute also employs numerous talents in over forty different professions. 900 research support staff contribute to the preparation and development of scientific and entrepreneurial projects that have a worldwide impact.
    					</p>
    				</div>
            			
	<h4 >Instruction to apply</h4>
	<div class="text-justify">
		
	</div>
				
	<p class="text-justify">
		<strong>Defence Security : </strong>
		<br/>
		This position is likely to be situated in a restricted area (ZRR), as defined in Decree No. 2011-1425 relating to the protection of national scientific and technical potential (PPST).Authorisation to enter an area is granted by the director of the unit, following a favourable Ministerial decision, as defined in the decree of 3 July 2012 relating to the PPST. An unfavourable Ministerial decision in respect of a position situated in a ZRR would result in the cancellation of the appointment.
    </p>
             	
    <p class="text-justify">
    	<strong> Recruitment Policy :</strong>
        <br/>
		As part of its diversity policy, all Inria positions are accessible to people with disabilities.
    </p>
        <p class="text-justify alert alert-warning">
		<b>Warning</b> : you must enter your e-mail address in order to save your application to Inria. Applications must be submitted online on the Inria website. Processing of applications sent from other channels is not guaranteed.
    </p>
    
             </div>
        </div>
    </div>
</div>

<!-- Modal Creer son compte -->
<div class="modal fade" id="registerOffre" tabindex="-1" role="dialog" aria-labelledby="myModalLabel">
    <div class="modal-dialog" role="document">
        <div class="modal-content ">
            
            <div class="modal-body">
              	<div class="row">
                  	<div class="col-md-6 pull-right">
                  		<button type="button" class="close" data-dismiss="modal" aria-label="Close"><i class="fa fa-remove"></i></button>
                  	</div>
            	</div>
            	<div class="row">
					<div class="col-md-6">
						<div class="form-group">
                        <p class="h4-inria list-group-item-text text-center">
                        I create my account
                        </p> 
                        <p class="h4 list-group-item-text text-center "> 
             			<i class="fa fa-info-circle"></i>
             			 To follow your application online 
                        </p>
            			<p class="h3 list-group-item-text text-center">
                           	<a href="https://jobs.inria.fr/public/en/register?ref=2023-05881"  class=" btn btn-danger">
	        	        		<i class="fa fa-plus"></i> Register
           					</a>
        				</p>
             			
                        </div>
       				</div>
           
           			<div class="col-md-6"  style="border-left: 1px solid #CCC;">
           				<div class="form-group">
           			
                        <p class="h4-inria list-group-item-text text-center">
							I already have an account!
                        </p> 
            			<p class="h3 list-group-item-text text-center">
                           	<a href="https://jobs.inria.fr/public/classic/en/offres/2023-05881/postuler"  class=" btn btn-danger">
	        	        		<i class="fa fa-sign-in"></i> Sign in
           					</a>
        				</p>
        				</div>
       				</div>
            	</div>
        	</div>
            <div class="modal-footer" style="border: none;">
                <button type="button" class="btn btn-default" data-dismiss="modal">Cancel </button>
            </div>
            
        </div>
    </div>
</div>

<script type="text/javascript" src="../../../../library/bootstrap-select-1.12.2/dist/js/bootstrap-select.min.js"></script>
        <script type="text/javascript" src="../../../../js/moment.js"></script>
		<script type="text/javascript" src="../../../../js/bootstrap-datetimepicker.js"></script>
		<script src="../../../../js/cookiechoices.js"></script>
		<script>
				var textCookie = "By continuing to browse this website, you consent to the use of cookies to offer you content and services in line with your interests.";
		var textBtnCookie = "See more";
		var textAccept = "I accept";
				document.addEventListener('DOMContentLoaded', function(event){cookieChoices.showCookieConsentBar(
				textCookie, textAccept, textBtnCookie, '/public/en/mentions-legales');
		});
		</script>

		<script type="text/javascript">

		 ScrollToTop = function() {
             var screen = $(window).scrollTop();
             if (screen > 100) {
               $('.scrollup').fadeIn();
             } else {
               $('.scrollup').fadeOut();
             }
         }
		 $('.scrollup').on('mouseover', function(){
             $(this).addClass('scrollup-mouseover');
             $(this).removeClass('scrollup-mouseout');
            });
         $('.scrollup').on('mouseout', function(){
             $(this).addClass('scrollup-mouseout');
             $(this).removeClass('scrollup-mouseover');
            });

         $('.scrollup').on('click',function () {
             $("html, body").animate({ scrollTop: 0 }, 500);

             return false;
         });

         StopAnimation = function() {
            $("html, body").bind("scroll mousedown DOMMouseScroll mousewheel keyup", function(){
                $('html, body').stop();
            });
         }

         $(window).scroll(function() {
             ScrollToTop();
             StopAnimation();
         });

		</script>


        <!-- Piwik -->
                <script type="text/javascript">
          var _paq = _paq || [];
          /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
          _paq.push(['trackPageView']);
          _paq.push(['enableLinkTracking']);
          (function() {
            var u="//piwik.inria.fr/";
            _paq.push(['setTrackerUrl', u+'piwik.php']);
            _paq.push(['setSiteId', '74']);
            var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
            g.type='text/javascript'; g.async=true; g.defer=true; g.src=u+'piwik.js'; s.parentNode.insertBefore(g,s);
          })();
        </script>
                <!-- End Piwik Code -->
    <script type="text/javascript">
    $(document).ready( function(){
        $("postulerOffre").on('click', function(){
            $('#postulerOffre').modal();
        });
    });
    </script>
    
</div>

<footer class="footer">
    <div class="col-md-12 text-center">
            <span class="text-center text-links-footer">
            <a href="../../../en/contact.html"  target="_blank">Contact</a>&nbsp;&nbsp;|&nbsp;
            <a href="../../../en/mentions-legales.html" target="_blank">Legal notice</a>
                        </span>
    </div>
</footer>
<script src="https://commons.inria.fr/bootstrap/ie10-fixup/ie10-viewport-bug-workaround.js"></script><script type="text/javascript" src="../../../../library/bootstrap-select-1.12.2/dist/js/bootstrap-select.min.js"></script>
        <script type="text/javascript" src="../../../../js/moment.js"></script>
		<script type="text/javascript" src="../../../../js/bootstrap-datetimepicker.js"></script>
		<script src="../../../../js/cookiechoices.js"></script>
		<script>
				var textCookie = "By continuing to browse this website, you consent to the use of cookies to offer you content and services in line with your interests.";
		var textBtnCookie = "See more";
		var textAccept = "I accept";
				document.addEventListener('DOMContentLoaded', function(event){cookieChoices.showCookieConsentBar(
				textCookie, textAccept, textBtnCookie, '/public/en/mentions-legales');
		});
		</script>

		<script type="text/javascript">

		 ScrollToTop = function() {
             var screen = $(window).scrollTop();
             if (screen > 100) {
               $('.scrollup').fadeIn();
             } else {
               $('.scrollup').fadeOut();
             }
         }
		 $('.scrollup').on('mouseover', function(){
             $(this).addClass('scrollup-mouseover');
             $(this).removeClass('scrollup-mouseout');
            });
         $('.scrollup').on('mouseout', function(){
             $(this).addClass('scrollup-mouseout');
             $(this).removeClass('scrollup-mouseover');
            });

         $('.scrollup').on('click',function () {
             $("html, body").animate({ scrollTop: 0 }, 500);

             return false;
         });

         StopAnimation = function() {
            $("html, body").bind("scroll mousedown DOMMouseScroll mousewheel keyup", function(){
                $('html, body').stop();
            });
         }

         $(window).scroll(function() {
             ScrollToTop();
             StopAnimation();
         });

		</script>


        <!-- Piwik -->
                <script type="text/javascript">
          var _paq = _paq || [];
          /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
          _paq.push(['trackPageView']);
          _paq.push(['enableLinkTracking']);
          (function() {
            var u="//piwik.inria.fr/";
            _paq.push(['setTrackerUrl', u+'piwik.php']);
            _paq.push(['setSiteId', '74']);
            var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
            g.type='text/javascript'; g.async=true; g.defer=true; g.src=u+'piwik.js'; s.parentNode.insertBefore(g,s);
          })();
        </script>
                <!-- End Piwik Code -->
    <script type="text/javascript">
    $(document).ready( function(){
        $("postulerOffre").on('click', function(){
            $('#postulerOffre').modal();
        });
    });
    </script>
</body>
</html>
