<!DOCTYPE html>
<html xmlns:og="http://opengraphprotocol.org/schema/">
    <head>
        <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
        <meta http-equiv="content-type" content="text/html; charset=utf-8" />
        <title>	2023-06090 - PhD Position F/M DOCT2023-STARS Computer Vision / Action Detection in Untrimmed Videos based on Transformers
</title>
        <link rel="icon" type="image/x-icon" href="../../../../favicon-16x16.png"/>
        <script type="text/javascript" src="../../../../js/jquery/jquery-1.9.1.js"></script>
        <script type="text/javascript" src="../../../../css/bootstrap-3.3.4/js/bootstrap.js"></script>
        	<meta property="og:description" content="Offre d'emploi Inria" />
	<meta property="og:title" content="PhD Position F/M DOCT2023-STARS Computer Vision / Action Detection in Untrimmed Videos based on Transformers" />
	<meta property="og:url" content="http://jobs.inria.fr/public/classic/fr/offres/2023-06090" />
	<meta property="og:locale" content="fr_FR" />
	<meta property="og:site_name" content="Inria"/>
	<meta property="og:type" content="article" />
        	            <link rel="stylesheet" href="../../../../css/bootstrap-3.3.4/css/bootstrap.min.css"/>
            <link rel="stylesheet" href="../../../../library/bootstrap-select-1.12.2/dist/css/bootstrap-select.min.css"/>
            <link rel="stylesheet" href="../../../../css/bootstrap/bootstrap-datetimepicker.css"/>
            <link rel="stylesheet" href="../../../../library/font-awesome-4.7.0/css/font-awesome.css"/>
            <link rel="stylesheet" href="../../../../css/fonts/fonts.css"/>
            <link rel="stylesheet" href="../../../../css/app/main_public.css" />
            <link rel="stylesheet" href="../../../../css/inria.css"/>
        
	<link property="stylesheet" rel="stylesheet" href="../../../../css/app/detailOffre.css" />
    </head>
<body  style="background-image: url('../../../../images/bg-jobs.png') ">
    
<nav id="toplinklist" class="nav navbar-nav navbar-default navbar-fixed-top" >
    <div class="navbar-inner">
        <div class="container">
            <div class="navbar-header">
                                <a href="../offres.html" class="pull-left inriatoplinklogo">
                    <img alt="Inria" width="30%" src="https://commons.inria.fr/images/logo/inr_logo_sans_sign_rouge.jpg" />
                </a>
                                <button type="button" class="navbar-toggle toplinktoggle" data-toggle="collapse" data-target="#navbar-collapse-menuTop">
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
            </div>
            <div class="collapse navbar-collapse" id="navbar-collapse-menuTop">
                <ul class="nav navbar-nav navbar-right">
                                        <li class="visible-xs text-right toplinktoggle-remove nav-profil-menu" data-toggle="collapse" data-target="#navbar-collapse-menuTop">
                        <i class="inria-gray3 fa fa-remove fa-2x"></i></li>
                    <li class=" text-center picto-lang nav-profil-menu" >
                                                                         <span class="toplang-button">
                             <a class="a-inria" href="2023-06090.html" >FR</a> <span class="inria-gray2">|</span>
                             <a class="inria-gray2" href="../../en/offres/2023-06090.html" title="English">
                                EN
                            </a>
                        </span>
                                            </li>

                                                                                                    <li class="dropdown text-center nav-profil-menu">
                        <a href="2023-06090.html#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">
                            <img alt="user" src="../../../../images/user.png">
                                                        <p style="color: black;">
                                Compte <span class="caret"></span>
                            </p>
                                                    </a>
                        <ul class="dropdown-menu">
                                                        <li><a href="../../../fr/connect.html"> <span class="fa fa-sign-in"></span> Se connecter</a></li>
                            <li><a href="../../../fr/register.html"><span class="fa fa-plus"></span> Créer un compte</a></li>
                                                    </ul>
                    </li>
                                </ul>
            </div><!-- /.navbar-collapse -->
          </div><!-- /.container -->
    </div><!-- /.navbar-inner -->
</nav>


<!-- Bouton Scroll -->
<div class="row">
    <div class="col-md-12">
        <div class="visible-sm visible-xs">
            <a href="2023-06090.html#" title="Haut de page" class="scrollup scrollup-sm link-btn" type="button">
                <i class="fa fa-chevron-up"></i>
            </a>
        </div>
        <div class="visible-md">
            <a href="2023-06090.html#" title="Haut de page" class="scrollup scrollup-md link-btn" type="button">
                <i class="fa fa-chevron-up"></i>
            </a>
        </div>
        <div class="visible-lg">
            <a href="2023-06090.html#" title="Haut de page" class="scrollup scrollup-lg link-btn" type="button">
                <i class="fa fa-chevron-up"></i>
            </a>
        </div>
    </div>
</div>
<!-- Main content -->
<div class="col-md-12 main-content" style="height:auto;">
    <div class="row">
        <div class="col-xs-10 col-xs-offset-1 col-lg-8 col-lg-offset-2 menu-breadcrumb">
            <a href="https://jobs.inria.fr/public/classic/fr/offres?locale=fr" class="a-inria">
        Accueil
        </a>
         > 
        <a href="https://jobs.inria.fr/public/classic/fr/offres?locale=fr" class="a-inria">Liste des offres</a>
         > Détail d&#039;une offre        </div>
    </div>
    <div class="row" ><div  class="col-xs-10 col-xs-offset-1 col-md-8 col-lg-6 col-lg-offset-2"></div></div>
<div class="row">
    <div class="col-md-12 col-lg-10 col-lg-offset-1">
        <div class="row">
                    
                <div id="left" class="col-sm-7 col-lg-6 col-lg-offset-1 block-left">
                    <div class="list-group list-group-item" style="padding: 6%; font-size: 16px;">
                                              <div class="row">
                            <span class="h4-inria intitule-detail-offre col-xs-10 col-sm-11"> 
                                <b>2023-06090 - PhD Position F/M DOCT2023-STARS Computer Vision / Action Detection in Untrimmed Videos based on Transformers</b>
                            </span>
                            <span class=" col-xs-2 col-sm-1">
                            <a class="a-inria" class="pdf-link"  href="https://jobs.inria.fr/public/classic/fr/offres/2023-06090/topdf" title="PDF">
                            	<i class="fa fa-file-pdf-o fa-2x pull-right"></i>
                            </a>
                            </span> 
                        </div>
                        <div class="row">
                         <span class=" h4 col-xs-10 col-sm-11"> 
                                                                                   <i class="fa fa-info-circle"></i> <em>Le descriptif de l’offre ci-dessous est en Anglais</em>
                                                                               </span>
                        </div>
                                						
		<div class="grand-item-offre">
		
				<div class="item-offre">	    	
	    	<p class="list-group-item-text"><b>Type de contrat : </b>
	        	CDD
	        </p>	        
	    </div>
	    	    
	    	    
	    	    <div class="item-offre">
	    	<p class="list-group-item-text"><b>Niveau de diplôme exigé : </b>
	        	Bac + 5 ou équivalent
	        </p>
	    </div>
	    	    
	    	    
	    	    
	    		<div class="item-offre">
	    	<p class="list-group-item-text"><b>Fonction : </b>
	        	Doctorant
	        </p>
	    </div>
	    	    
	    	    
	    	    
	        </div>
    
        
        <div class="grand-item-offre">
    	<h4 class="list-group-item-heading">A propos du centre ou de la direction fonctionnelle</h4>
    	<div class="list-group-item-text text-justify">
    		<p>The Inria Universit&eacute; C&ocirc;te d'Azur center counts 37 research teams as well as 8 support services. The center's staff (about 500 people) is made up of scientists of diﬀerent nationalities, engineers, technicians and administrative staff. The majority of the center's research teams are located in Sophia Antipolis and five of them are based in an Inria antenna in Montpellier. The Inria branch in Montpellier is growing in size, in accordance with the strategy described in the institution's Contract of Objectives and Performance (COP).</p>
    	</div>
    </div>
        
        <div class="grand-item-offre">
    	<h4 class="list-group-item-heading">Contexte et atouts du poste</h4>
    	<div class="list-group-item-text text-justify">
    		<p>Inria, the French National Institute for computer science and applied mathematics, promotes &ldquo;scientific excellence for technology transfer and society&rdquo;. Graduates from the world&rsquo;s top universities, Inria's 2,700 employees rise to the challenges of digital sciences. With its open, agile model, Inria is able to explore original approaches with its partners in industry and academia and provide an efficient response to the multidisciplinary and application challenges of digital transformation. Inria is the source of many innovations that add value and create jobs.</p>
<p><strong>Team </strong></p>
<p>The STARS research team combines advanced theory with a cutting-edge practice focusing on cognitive vision systems.</p>
<p><strong><em>Team web site : </em></strong><em><a>https://team.inria.fr/stars/</a></em></p>
<p>&nbsp;</p>
<p>Scientific context</p>
<p>STARS group works on automatic video monitoring and human behavior understanding for health applications. The Deep Learning platform developed in STARS, detects mobile objects, tracks their trajectory, and recognizes related behaviors predefined by experts.</p>
<p>Action detection is a challenging computer vision problem that targets at finding precise temporal boundaries of actions occurring in an untrimmed video. Many studies on action detection focus on videos with sparse and well-separated instances of action. For instance, action detection algorithms on popular datasets like THUMOS and ActivityNet generally learn representations for single actions in a video. However, in daily life, human actions are continuous and can be very dense. Every minute is filled with potential actions to be detected and labeled. The methods designed for sparsely labeled datasets are hard to generalize to such real-world scenarios.</p>
<p>Towards this research direction, several methods [2, 3, 5] have been proposed to model complex temporal relationships and to process datasets like Charades, TSU [1], and MultiTHUMOS. Those datasets encompassing real-world challenges share the following characteristics: Firstly, the actions are densely labeled and background instances are rare in these videos compared to sparsely labeled datasets. Secondly, the video has a rich temporal structure and a set of actions occurring together often follows a well-defined temporal pattern. For example, &ldquo;drinking from the bottle&rdquo; always happens after &ldquo;taking a bottle&rdquo; and &ldquo;reading a book&rdquo; is also related to &ldquo;opening a book&rdquo;. Moreover, humans are great at multitasking, multiple actions can co-occur at the same time. For example, &ldquo;reading books&rdquo; while &ldquo;drinking water&rdquo;.</p>
<p>&nbsp;</p>
<p>So, the main question is how semantics can be modeled to help recognize complex temporal relationships in videos.</p>
<p>Typical situations that we would like to monitor are Eating and Drinking (how much? how often?) or Cooking (detect behavior that might lead to dangerous situations or non-completion of the task).</p>
<p>The system we want to develop will help senior people and their relatives to feel more comfortable at their homes since scene understanding intends to help at recognizing potentially dangerous situations and reporting to caregivers if necessary.</p>
<p>&nbsp;</p>
    	</div>
    </div>
        
        <div class="grand-item-offre">
    	<h4 class="list-group-item-heading">Mission confiée</h4>
    	<div class="list-group-item-text text-justify">
    		<p>In this work, we would like to go beyond Deep Learning by incorporating some semantic modelling within the Deep Learning pipeline, which consists of a combination of CNN and transformers [5] to be able to model the complex action patterns in untrimmed videos. These complex action patterns could include composite actions and concurrent actions existing in long untrimmed videos.</p>
<p>Existing methods [3, 5, 6] have mostly focused on modelling the variation of visual cues across time locally or globally within a video. However, these methods consider temporal information without any further semantics. Real-world videos contain many complex actions with inherent relationships between action classes at the same time steps or across distant time steps. Modelling such class-temporal relationships can be extremely useful for locating actions in those videos.</p>
<p>In this work, we focus on semantic modelling for improving action detection performance. Videos may contain rich semantic information such as objects, actions, and scenes. Relationships among different semantics are high-level knowledge which is critical for understanding the video content. Therefore, semantic relational reasoning can help determine the action instance occurrences and locate the actions in the video, especially for complex actions in the video. For handling these challenges, Class-Temporal Relational Network (CTRN) [4] has been proposed to explore both the class and temporal relations of detected actions.</p>
<p>To go beyond the above, a first attempt may consist to:</p>
<p>(1) Effectively extracting action-relevant semantics from real-world untrimmed videos.</p>
<p>(2) Modelling the cross-semantic relations to enhance the action detection performance.</p>
<p>(3) Incorporate the modelled semantics within the Deep Learning pipeline.</p>
<p>To extract the relevant semantics, large Language-Vision models could be used.</p>
<p>This work will be conducted within the Cobtek team from Nice Hospital, who is specialized in clinical trials for older adults with dementia.</p>
<p>The evaluation of proposed frameworks and models should be performed on public datasets which contain everyday activities like Charades, MultiTHUMOS, and homecare datasets like TSU [1].</p>
<p>There is a possibility of conducting first an internship, before the PhD thesis</p>
<p>&nbsp;</p>
<p>A state of the art, bibliography and scientific references are available at the following URL, do not hesitate to log in: <a href="http://www-sop.inria.fr/members/Francois.Bremond/">http://www-sop.inria.fr/members/Francois.Bremond/</a></p>
<p>Schedule:</p>
<p>1<sup>st</sup> year:</p>
<ul>
<li>Study the limitations of existing activity recognition algorithms.</li>
<li>Depending on the targeted activities, data collection might need to be carried out.</li>
<li>Propose an original algorithm that addresses current limitations on inference.</li>
<li>Evaluate the proposed algorithm on benchmarking datasets,</li>
<li>Write a paper</li>
</ul>
<p>&nbsp;</p>
<p>2<sup>nd</sup> year:</p>
<p>&nbsp;</p>
<ul>
<li>Investigation of feasibility/appropriateness of the framework in practical situations</li>
<li>Propose an algorithm to address model learning tasks in supervised settings</li>
<li>Writing papers</li>
</ul>
<p>3<sup>rd</sup> year:</p>
<ul>
<li>Optimize the proposed algorithm for real-world scenarios.</li>
<li>Writing papers and the PhD manuscript.</li>
</ul>
<p>&nbsp;</p>
<h1>&nbsp;</h1>
<h1>Bibliography:</h1>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>[1] Rui Dai, Srijan Das, Saurav Sharma, Luca Minciullo, Lorenzo Garattoni, Francois Bremond, and Gianpiero Francesca. Toyota smarthome untrimmed: Real-world untrimmed videos for activity detection. Transactions on Pattern Analysis and Machine Intelligence, TPAMI, ISSN: 0162-8828, Digital Object Identifier: 10.1109/TPAMI.2022.3169976, PAMI 2022.</p>
<p>&nbsp;</p>
<p>[2] Rui Dai, Srijan Das, and Francois Bremond. Learning an augmented RGB representation with crossmodal knowledge distillation for action detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pp. 13053&ndash;13064, October 2021.</p>
<p>&nbsp;</p>
<p>[3] Rui Dai, Srijan Das, Luca Minciullo, Lorenzo Garattoni, Gianpiero Francesca, and Francois Bremond. PDAN: Pyramid dilated attention network for action detection. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), pp. 2970&ndash;2979, January 2021.</p>
<p>&nbsp;</p>
<p>[4] R. Dai, S. Das and F. Bremond. CTRN: Class Temporal Relational Network For Action Detection. In Proceedings of the 32nd British Machine Vision Conference, BMVC 2021, hal-03383140v2, United Kingdom, Virtual, November 22-25, 2021.</p>
<p>&nbsp;</p>
<p>[5] R. Dai, S. Das, K. Kahatapitiya, M. Ryoo and F. Bremond. MS-TCT: Multi-Scale Temporal ConvTransformer for Action Detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2022, New Orleans, Hybrid, June 19-23, 2022.</p>
<p>&nbsp;</p>
<p>[6] AJ Piergiovanni and Michael S Ryoo. Temporal gaussian mixture layer for videos. International Conference on Machine Learning (ICML), 2019.</p>
    	</div>
    </div>
        
        <div class="grand-item-offre">
    	<h4 class="list-group-item-heading">Principales activités</h4>
    	<div class="list-group-item-text text-justify">
    		<p>The Inria STARS team is seeking for a Ph.D. researcher with strong background in computer vision, deep learning and machine learning.</p>
<p>The candidate is expected to conduct research related to the development of computer vision algorithms for video understanding.</p>
<p><strong>Main activities:</strong></p>
<ul>
<li>Analyze the requirements of doctors and&nbsp;patients/end-users and Study the limitations of existing solutions.</li>
<li>Propose&nbsp;a new algorithm for detecting the behaviors of patients/end-users</li>
<li>Evaluate and optimize proposed algorithm on the targeted video datasets</li>
<li>Oral presentation and Write reports</li>
<li>Submit a scientific paper to a conference</li>
</ul>
    	</div>
    </div>
        
        <div class="grand-item-offre">
		<h4 class="list-group-item-heading">Compétences</h4>
		<div class="list-group-item-text text-justify">
			<p>Candidates must hold a Master's degree or equivalent in Computer Science or a closely related discipline by the start date.</p>
<p>The candidate must be grounded in computer vision basics and have solid mathematical and programming skills.</p>
<p>With theoretical knowledge in Computer Vision, OpenCV, Mathematics, Deep Learning (PyTorch, TensorFlow), and technical background in C++ and Python programming, and Linux.</p>
<p>The candidate must be committed to scientific research and substantial publications.</p>
<p>In order to protect its scientific and technological assets, Inria is a restricted-access establishment. Consequently, it follows special regulations for welcoming any person who wishes to work with the institute. The final acceptance of each candidate thus depends on applying this security and defense procedure.</p>
		</div>
	</div>
	    
        <div class="grand-item-offre">
    	<h4 class="list-group-item-heading">Avantages</h4>
    	<div class="list-group-item-text text-justify">
    		<ul>
<li>&bull;&nbsp;&nbsp; &nbsp;Subsidized meals<br />&bull;&nbsp;&nbsp; &nbsp;Partial reimbursement of public transport costs<br />&bull;&nbsp;&nbsp; &nbsp;Leave: 7 weeks of annual leave + 10 extra days off due to RTT (statutory reduction in working hours) + possibility of exceptional leave (sick children, moving home, etc.)<br />&bull;&nbsp;&nbsp; &nbsp;Possibility of teleworking and flexible organization of working hours<br />&bull;&nbsp;&nbsp; &nbsp;Professional equipment available (videoconferencing, loan of computer equipment, etc.)<br />&bull;&nbsp;&nbsp; &nbsp;Social, cultural and sports events and activities<br />&bull;&nbsp;&nbsp; &nbsp;Access to vocational training<br />&bull;&nbsp;&nbsp; &nbsp;Contribution to mutual insurance (subject to conditions)</li>
</ul>
    	</div>
    </div>
        
        <div class="grand-item-offre">
    	<h4 class="list-group-item-heading">Rémunération</h4>
    	<div class="list-group-item-text text-justify">
    		<ul>
<li>Duration: 36 months<br />Location: Sophia Antipolis, France<br />Gross Salary per month: 2051&euro; brut per month (year 1 &amp; 2) and 2158&euro; brut per month (year 3)</li>
</ul>
    	</div>
    </div>
      
                    </div>
                </div>
        
                          <div id="right" class="col-sm-5 bloc-right">	
               
                	<div class="row">
                		<div class="col-sm-12" style="padding:15px;margin-bottom :10px;">
                     	                        	                           		<a href="2023-06090.html#" class="btn btn-lg btn-danger btn-postuler-footer" style="width:100%" data-toggle="modal" data-target="#registerOffre">Postuler</a>
                        	                    			
            			</div>
            		</div>
        		    	<h4 >Partager</h4>

		<ul class="social">
		<li><a target="_blank" href="https://www.facebook.com/sharer.php?u=http://jobs.inria.fr/public/classic/fr/offres/2023-06090&title=Offre+d%27emploi+Inria&description=PhD Position F/M DOCT2023-STARS Computer Vision / Action Detection in Untrimmed Videos based on Transformers" class="a-facebook btn btn-sm btn-danger"> <i class="fa fa-facebook"></i> </a></li>
		<li><a target="_blank" href="https://www.linkedin.com/shareArticle?mini=true&url=http://jobs.inria.fr/public/classic/fr/offres/2023-06090&title=Offre d'emploi Inria&summary=PhD Position F/M DOCT2023-STARS Computer Vision / Action Detection in Untrimmed Videos based on Transformers" class="a-linkedin btn btn-sm btn-danger"> <i class="fa fa-linkedin"></i> </a></li>
		<li><a target="_blank" href="http://twitter.com/share?hashtags=Jobs.inria.fr,Emploi,Sophia-Antipolis&text=Offre d'emploi Inria : PhD Position F/M DOCT2023-STARS Computer Vision / Action Detection in Untrimmed Videos based on Transformers%0A&url=http://jobs.inria.fr/public/classic/fr/offres/2023-06090" class="a-twitter btn btn-sm btn-danger"> <i class="fa fa-twitter"></i> </a></li>
		<li><a target="_blank" href="mailto:?body=Offre d'emploi Inria :%0A PhD Position F/M DOCT2023-STARS Computer Vision / Action Detection in Untrimmed Videos based on Transformers%0A%0A http://jobs.inria.fr/public/classic/fr/offres/2023-06090&subject=Offre d'emploi Inria: PhD Position F/M DOCT2023-STARS Computer Vision / Action Detection in Untrimmed Videos based on Transformers" class="a-envelope btn btn-sm btn-danger"> <i class="fa fa-envelope"></i> </a></li>
	</ul>
	
        				
	<h4 >Informations générales</h4>
	<ul class="nomargin">
									<li><strong>Thème/Domaine :</strong>
											Vision, perception et interprétation multimedia
						<br/>										
											Calcul Scientifique
													(BAP E)
																
				</li>
							
				<li><strong>Ville :</strong>
			Sophia-Antipolis
		</li>
				
				<li><strong>Centre Inria :</strong>
							<a class="a-inria" target="_blank" href="http://www.inria.fr/centre/sophia">Centre Inria d&#039;Université Côte d&#039;Azur</a>
					</li>  
						
					<li><strong>Date de prise de fonction souhaitée :</strong>
				2023-11-01
			</li>
							<li><strong>Durée de contrat :</strong>
					3 ans
				</li>
							
				<li><strong>Date limite pour postuler :</strong>
			2023-05-05				
		</li>
			</ul>
	
        				
	<h4 >Contacts</h4>
	<ul class="nomargin">
				<li><strong>Equipe Inria :</strong>
							<a class="a-inria" href="https://www.inria.fr/equipes/STARS" target="_blank">STARS</a>    	
								</li>
																			<li>
			<strong>Directeur de thèse :</strong>
			<br/>
			Brémond François
			/
			<a class="a-inria" href="mailto:Francois.Bremond@inria.fr">Francois.Bremond@inria.fr</a>
		</li>
	    	</ul>

        				
	    	<h4 >L&#039;essentiel pour réussir</h4>
    	<div class="text-justify">
    		<ul>
<li>Essential qualities in order to fulfil this assignment are feeling at ease in an environment of scientific dynamics and wanting to learn and listen.</li>
<li>Passionate about innovation, willing to go for a PhD thesis in the field of Computer Vision and Machine Learning.</li>
</ul>
<p>Languages: English</p>
<ul>
<li>Relational skills: team work</li>
<li>Other valued appreciated: leadership</li>
</ul>
    	</div>
    
        			<div class="grand-item-offre">
    					<h4 class="list-group-item-heading">A propos d&#039;Inria</h4>
    					<p class="list-group-item-text text-justify">
    		            Inria est l’institut national de recherche dédié aux sciences et technologies du numérique. Il emploie 2600 personnes. Ses 200 équipes-projets agiles, en général communes avec des partenaires académiques, impliquent plus de 3500 scientifiques pour relever les défis du numérique, souvent à l’interface d’autres disciplines. L’institut fait appel à de nombreux talents dans plus d’une quarantaine de métiers différents. 900 personnels d’appui à la recherche et à l’innovation contribuent à faire émerger et grandir des projets scientifiques ou entrepreneuriaux qui impactent le monde. Inria travaille avec de nombreuses entreprises et a accompagné la création de plus de 180 start-up. L&#039;institut s&#039;eﬀorce ainsi de répondre aux enjeux de la transformation numérique de la science, de la société et de l&#039;économie.
    					</p>
    				</div>
            			
	<h4 >Consignes pour postuler</h4>
	<div class="text-justify">
		<p>Before applying, it is strongly recommended that you contact the Scientific manager beforehand.</p>
	</div>
				
	<p class="text-justify">
		<strong>Sécurité défense : </strong>
		<br/>
		Ce poste est susceptible d’être affecté dans une zone à régime restrictif (ZRR), telle que définie dans le décret n°2011-1425 relatif à la protection du potentiel scientifique et technique de la nation (PPST). L’autorisation d’accès à une zone est délivrée par le chef d’établissement, après avis ministériel favorable, tel que défini dans l’arrêté du 03 juillet 2012, relatif à la PPST. Un avis ministériel défavorable pour un poste affecté dans une ZRR aurait pour conséquence l’annulation du recrutement.
    </p>
             	
    <p class="text-justify">
    	<strong> Politique de recrutement :</strong>
        <br/>
		Dans le cadre de sa politique diversité, tous les postes Inria sont accessibles aux personnes en situation de handicap.
    </p>
        <p class="text-justify alert alert-warning">
		<b>Attention</b>: Les candidatures doivent être déposées en ligne sur le site Inria. Le traitement des candidatures adressées par d'autres canaux n'est pas garanti.
    </p>
    
             </div>
        </div>
    </div>
</div>

<!-- Modal Creer son compte -->
<div class="modal fade" id="registerOffre" tabindex="-1" role="dialog" aria-labelledby="myModalLabel">
    <div class="modal-dialog" role="document">
        <div class="modal-content ">
            
            <div class="modal-body">
              	<div class="row">
                  	<div class="col-md-6 pull-right">
                  		<button type="button" class="close" data-dismiss="modal" aria-label="Close"><i class="fa fa-remove"></i></button>
                  	</div>
            	</div>
            	<div class="row">
					<div class="col-md-6">
						<div class="form-group">
                        <p class="h4-inria list-group-item-text text-center">
                        Je crée mon compte
                        </p> 
                        <p class="h4 list-group-item-text text-center "> 
             			<i class="fa fa-info-circle"></i>
             			 Pour suivre votre candidature
                        </p>
            			<p class="h3 list-group-item-text text-center">
                           	<a href="https://jobs.inria.fr/public/fr/register?ref=2023-06090"  class=" btn btn-danger">
	        	        		<i class="fa fa-plus"></i> Créer un compte
           					</a>
        				</p>
             			
                        </div>
       				</div>
           
           			<div class="col-md-6"  style="border-left: 1px solid #CCC;">
           				<div class="form-group">
           			
                        <p class="h4-inria list-group-item-text text-center">
							J&#039;ai déjà un compte!
                        </p> 
            			<p class="h3 list-group-item-text text-center">
                           	<a href="https://jobs.inria.fr/public/classic/fr/offres/2023-06090/postuler"  class=" btn btn-danger">
	        	        		<i class="fa fa-sign-in"></i> Se connecter
           					</a>
        				</p>
        				</div>
       				</div>
            	</div>
        	</div>
            <div class="modal-footer" style="border: none;">
                <button type="button" class="btn btn-default" data-dismiss="modal">Annuler </button>
            </div>
            
        </div>
    </div>
</div>

<script type="text/javascript" src="../../../../library/bootstrap-select-1.12.2/dist/js/bootstrap-select.min.js"></script>
        <script type="text/javascript" src="../../../../js/moment.js"></script>
		<script type="text/javascript" src="../../../../js/bootstrap-datetimepicker.js"></script>
		<script src="../../../../js/cookiechoices.js"></script>
		<script>
				var textCookie = "En poursuivant votre navigation sur ce site vous acceptez l'utilisation des cookies pour vous proposer des contenus et services adaptés à vos centres d'intérêts.";
		var textBtnCookie = 'En savoir plus';
		var textAccept = "J'accepte";
				document.addEventListener('DOMContentLoaded', function(event){cookieChoices.showCookieConsentBar(
				textCookie, textAccept, textBtnCookie, '/public/fr/mentions-legales');
		});
		</script>

		<script type="text/javascript">

		 ScrollToTop = function() {
             var screen = $(window).scrollTop();
             if (screen > 100) {
               $('.scrollup').fadeIn();
             } else {
               $('.scrollup').fadeOut();
             }
         }
		 $('.scrollup').on('mouseover', function(){
             $(this).addClass('scrollup-mouseover');
             $(this).removeClass('scrollup-mouseout');
            });
         $('.scrollup').on('mouseout', function(){
             $(this).addClass('scrollup-mouseout');
             $(this).removeClass('scrollup-mouseover');
            });

         $('.scrollup').on('click',function () {
             $("html, body").animate({ scrollTop: 0 }, 500);

             return false;
         });

         StopAnimation = function() {
            $("html, body").bind("scroll mousedown DOMMouseScroll mousewheel keyup", function(){
                $('html, body').stop();
            });
         }

         $(window).scroll(function() {
             ScrollToTop();
             StopAnimation();
         });

		</script>


        <!-- Piwik -->
                <script type="text/javascript">
          var _paq = _paq || [];
          /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
          _paq.push(['trackPageView']);
          _paq.push(['enableLinkTracking']);
          (function() {
            var u="//piwik.inria.fr/";
            _paq.push(['setTrackerUrl', u+'piwik.php']);
            _paq.push(['setSiteId', '74']);
            var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
            g.type='text/javascript'; g.async=true; g.defer=true; g.src=u+'piwik.js'; s.parentNode.insertBefore(g,s);
          })();
        </script>
                <!-- End Piwik Code -->
    <script type="text/javascript">
    $(document).ready( function(){
        $("postulerOffre").on('click', function(){
            $('#postulerOffre').modal();
        });
    });
    </script>
    
</div>

<footer class="footer">
    <div class="col-md-12 text-center">
            <span class="text-center text-links-footer">
            <a href="../../../fr/contact.html"  target="_blank">Contact</a>&nbsp;&nbsp;|&nbsp;
            <a href="../../../fr/mentions-legales.html" target="_blank">Mentions légales</a>
                        </span>
    </div>
</footer>
<script src="https://commons.inria.fr/bootstrap/ie10-fixup/ie10-viewport-bug-workaround.js"></script><script type="text/javascript" src="../../../../library/bootstrap-select-1.12.2/dist/js/bootstrap-select.min.js"></script>
        <script type="text/javascript" src="../../../../js/moment.js"></script>
		<script type="text/javascript" src="../../../../js/bootstrap-datetimepicker.js"></script>
		<script src="../../../../js/cookiechoices.js"></script>
		<script>
				var textCookie = "En poursuivant votre navigation sur ce site vous acceptez l'utilisation des cookies pour vous proposer des contenus et services adaptés à vos centres d'intérêts.";
		var textBtnCookie = 'En savoir plus';
		var textAccept = "J'accepte";
				document.addEventListener('DOMContentLoaded', function(event){cookieChoices.showCookieConsentBar(
				textCookie, textAccept, textBtnCookie, '/public/fr/mentions-legales');
		});
		</script>

		<script type="text/javascript">

		 ScrollToTop = function() {
             var screen = $(window).scrollTop();
             if (screen > 100) {
               $('.scrollup').fadeIn();
             } else {
               $('.scrollup').fadeOut();
             }
         }
		 $('.scrollup').on('mouseover', function(){
             $(this).addClass('scrollup-mouseover');
             $(this).removeClass('scrollup-mouseout');
            });
         $('.scrollup').on('mouseout', function(){
             $(this).addClass('scrollup-mouseout');
             $(this).removeClass('scrollup-mouseover');
            });

         $('.scrollup').on('click',function () {
             $("html, body").animate({ scrollTop: 0 }, 500);

             return false;
         });

         StopAnimation = function() {
            $("html, body").bind("scroll mousedown DOMMouseScroll mousewheel keyup", function(){
                $('html, body').stop();
            });
         }

         $(window).scroll(function() {
             ScrollToTop();
             StopAnimation();
         });

		</script>


        <!-- Piwik -->
                <script type="text/javascript">
          var _paq = _paq || [];
          /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
          _paq.push(['trackPageView']);
          _paq.push(['enableLinkTracking']);
          (function() {
            var u="//piwik.inria.fr/";
            _paq.push(['setTrackerUrl', u+'piwik.php']);
            _paq.push(['setSiteId', '74']);
            var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
            g.type='text/javascript'; g.async=true; g.defer=true; g.src=u+'piwik.js'; s.parentNode.insertBefore(g,s);
          })();
        </script>
                <!-- End Piwik Code -->
    <script type="text/javascript">
    $(document).ready( function(){
        $("postulerOffre").on('click', function(){
            $('#postulerOffre').modal();
        });
    });
    </script>
</body>
</html>
