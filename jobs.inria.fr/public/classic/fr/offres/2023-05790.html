<!DOCTYPE html>
<html xmlns:og="http://opengraphprotocol.org/schema/">
    <head>
        <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
        <meta http-equiv="content-type" content="text/html; charset=utf-8" />
        <title>	2023-05790 - Doctorant F/H Inversion acoustique articulatoire de la parole à l’aide d’images IRM dynamiques
</title>
        <link rel="icon" type="image/x-icon" href="../../../../favicon-16x16.png"/>
        <script type="text/javascript" src="../../../../js/jquery/jquery-1.9.1.js"></script>
        <script type="text/javascript" src="../../../../css/bootstrap-3.3.4/js/bootstrap.js"></script>
        	<meta property="og:description" content="Offre d'emploi Inria" />
	<meta property="og:title" content="Doctorant F/H Inversion acoustique articulatoire de la parole à l’aide d’images IRM dynamiques" />
	<meta property="og:url" content="http://jobs.inria.fr/public/classic/fr/offres/2023-05790" />
	<meta property="og:locale" content="fr_FR" />
	<meta property="og:site_name" content="Inria"/>
	<meta property="og:type" content="article" />
        	            <link rel="stylesheet" href="../../../../css/bootstrap-3.3.4/css/bootstrap.min.css"/>
            <link rel="stylesheet" href="../../../../library/bootstrap-select-1.12.2/dist/css/bootstrap-select.min.css"/>
            <link rel="stylesheet" href="../../../../css/bootstrap/bootstrap-datetimepicker.css"/>
            <link rel="stylesheet" href="../../../../library/font-awesome-4.7.0/css/font-awesome.css"/>
            <link rel="stylesheet" href="../../../../css/fonts/fonts.css"/>
            <link rel="stylesheet" href="../../../../css/app/main_public.css" />
            <link rel="stylesheet" href="../../../../css/inria.css"/>
        
	<link property="stylesheet" rel="stylesheet" href="../../../../css/app/detailOffre.css" />
    </head>
<body  style="background-image: url('../../../../images/bg-jobs.png') ">
    
<nav id="toplinklist" class="nav navbar-nav navbar-default navbar-fixed-top" >
    <div class="navbar-inner">
        <div class="container">
            <div class="navbar-header">
                                <a href="../offres.html" class="pull-left inriatoplinklogo">
                    <img alt="Inria" width="30%" src="https://commons.inria.fr/images/logo/inr_logo_sans_sign_rouge.jpg" />
                </a>
                                <button type="button" class="navbar-toggle toplinktoggle" data-toggle="collapse" data-target="#navbar-collapse-menuTop">
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
            </div>
            <div class="collapse navbar-collapse" id="navbar-collapse-menuTop">
                <ul class="nav navbar-nav navbar-right">
                                        <li class="visible-xs text-right toplinktoggle-remove nav-profil-menu" data-toggle="collapse" data-target="#navbar-collapse-menuTop">
                        <i class="inria-gray3 fa fa-remove fa-2x"></i></li>
                    <li class=" text-center picto-lang nav-profil-menu" >
                                                                         <span class="toplang-button">
                             <a class="a-inria" href="2023-05790.html" >FR</a> <span class="inria-gray2">|</span>
                             <a class="inria-gray2" href="../../en/offres/2023-05790.html" title="English">
                                EN
                            </a>
                        </span>
                                            </li>

                                                                                                    <li class="dropdown text-center nav-profil-menu">
                        <a href="2023-05790.html#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">
                            <img alt="user" src="../../../../images/user.png">
                                                        <p style="color: black;">
                                Compte <span class="caret"></span>
                            </p>
                                                    </a>
                        <ul class="dropdown-menu">
                                                        <li><a href="../../../fr/connect.html"> <span class="fa fa-sign-in"></span> Se connecter</a></li>
                            <li><a href="../../../fr/register.html"><span class="fa fa-plus"></span> Créer un compte</a></li>
                                                    </ul>
                    </li>
                                </ul>
            </div><!-- /.navbar-collapse -->
          </div><!-- /.container -->
    </div><!-- /.navbar-inner -->
</nav>


<!-- Bouton Scroll -->
<div class="row">
    <div class="col-md-12">
        <div class="visible-sm visible-xs">
            <a href="2023-05790.html#" title="Haut de page" class="scrollup scrollup-sm link-btn" type="button">
                <i class="fa fa-chevron-up"></i>
            </a>
        </div>
        <div class="visible-md">
            <a href="2023-05790.html#" title="Haut de page" class="scrollup scrollup-md link-btn" type="button">
                <i class="fa fa-chevron-up"></i>
            </a>
        </div>
        <div class="visible-lg">
            <a href="2023-05790.html#" title="Haut de page" class="scrollup scrollup-lg link-btn" type="button">
                <i class="fa fa-chevron-up"></i>
            </a>
        </div>
    </div>
</div>
<!-- Main content -->
<div class="col-md-12 main-content" style="height:auto;">
    <div class="row">
        <div class="col-xs-10 col-xs-offset-1 col-lg-8 col-lg-offset-2 menu-breadcrumb">
            <a href="https://jobs.inria.fr/public/classic/fr/offres?locale=fr" class="a-inria">
        Accueil
        </a>
         > 
        <a href="https://jobs.inria.fr/public/classic/fr/offres?locale=fr" class="a-inria">Liste des offres</a>
         > Détail d&#039;une offre        </div>
    </div>
    <div class="row" ><div  class="col-xs-10 col-xs-offset-1 col-md-8 col-lg-6 col-lg-offset-2"></div></div>
<div class="row">
    <div class="col-md-12 col-lg-10 col-lg-offset-1">
        <div class="row">
                    
                <div id="left" class="col-sm-7 col-lg-6 col-lg-offset-1 block-left">
                    <div class="list-group list-group-item" style="padding: 6%; font-size: 16px;">
                                              <div class="row">
                            <span class="h4-inria intitule-detail-offre col-xs-10 col-sm-11"> 
                                <b>2023-05790 - Doctorant F/H Inversion acoustique articulatoire de la parole à l’aide d’images IRM dynamiques</b>
                            </span>
                            <span class=" col-xs-2 col-sm-1">
                            <a class="a-inria" class="pdf-link"  href="https://jobs.inria.fr/public/classic/fr/offres/2023-05790/topdf" title="PDF">
                            	<i class="fa fa-file-pdf-o fa-2x pull-right"></i>
                            </a>
                            </span> 
                        </div>
                        <div class="row">
                         <span class=" h4 col-xs-10 col-sm-11"> 
                                                  </span>
                        </div>
                                						
		<div class="grand-item-offre">
		
			    
	    	    
	    	    <div class="item-offre">
	    	<p class="list-group-item-text"><b>Niveau de diplôme exigé : </b>
	        	Bac + 5 ou équivalent
	        </p>
	    </div>
	    	    
	    	    
	    	    
	    		<div class="item-offre">
	    	<p class="list-group-item-text"><b>Fonction : </b>
	        	Doctorant
	        </p>
	    </div>
	    	    
	    	    
	    	    
	        </div>
    
        
        
        <div class="grand-item-offre">
    	<h4 class="list-group-item-heading">Contexte et atouts du poste</h4>
    	<div class="list-group-item-text text-justify">
    		<p>Ce projet est un projet de LUE (Lorraine Universit&eacute; d'Excellence) ; il sera men&eacute; conjointement au laboratoire Loria (&eacute;quipe Inria MultiSpeech) et au laboratoire IADI (INSERM U1254) qui collaborent ensemble depuis plusieurs ann&eacute;es sur l&rsquo;imagerie du conduit vocal et la production de la parole.</p>
<p>Cela permettra en particulier de faire appel au syst&egrave;me d'acquisition IRM bidimensionnelle en temps r&eacute;el (&agrave; 50 images par seconde) dont s&rsquo;est &eacute;quip&eacute; le laboratoire IADI dans le cadre d'une collaboration r&eacute;gionale avec Loria. Ce syst&egrave;me, unique en France, permet d&rsquo;imager le conduit vocal &agrave; une fr&eacute;quence de 50 Hz dans n&rsquo;importe quelle direction ce qui int&eacute;ressant pour la r&eacute;cup&eacute;ration de la fonction d&rsquo;aire.</p>
<p>Yves Laprie (<a href="mailto:Yves.Laprie@loria.fr">Yves.Laprie@loria.fr</a>) et Pierre-Andr&eacute; Vuissoz (<a href="mailto:pa.vuissoz@chru-nancy.fr">pa.vuissoz@chru-nancy.fr</a>) codirigeront cette th&egrave;se.</p>
    	</div>
    </div>
        
        <div class="grand-item-offre">
    	<h4 class="list-group-item-heading">Mission confiée</h4>
    	<div class="list-group-item-text text-justify">
    		<h2><strong>Enjeu scientifique</strong></h2>
<p>La synth&egrave;se articulatoire imite le processus de production de la parole en g&eacute;n&eacute;rant d'abord la forme du conduit vocal &agrave; partir de la suite de phon&egrave;mes &agrave; prononcer, puis le signal acoustique en r&eacute;solvant les &eacute;quations de l&rsquo;a&eacute;ro-acoustique [<a href="https://hal.archives-ouvertes.fr/hal-01199792v3">1</a>, <a href="https://hal.archives-ouvertes.fr/hal-01278462">2</a>]. Par rapport &agrave; d'autres approches de la synth&egrave;se de la parole qui offrent un niveau de qualit&eacute; tr&egrave;s &eacute;lev&eacute;, l&rsquo;int&eacute;r&ecirc;t est avant tout de contr&ocirc;ler l'ensemble du processus de production, au-del&agrave; du seul signal acoustique.</p>
<p>L&rsquo;objectif de ce contrat doctoral est de r&eacute;ussir la transformation inverse, appel&eacute;e inversion acoustique articulatoire, afin de retrouver la forme g&eacute;om&eacute;trique du conduit vocal &agrave; partir du signal acoustique. Un simple enregistrement de la voix permettra de suivre la dynamique des diff&eacute;rents articulateurs lors de la production de la phrase enregistr&eacute;e.</p>
<p>Au-del&agrave; de son int&eacute;r&ecirc;t en termes de d&eacute;fi scientifique, l&rsquo;inversion acoustique articulatoire a de nombreuses applications potentielles. Seule, elle peut &ecirc;tre utilis&eacute;e comme outil de diagnostic afin d&rsquo;&eacute;valuer les gestes articulatoires dans un cadre &eacute;ducatif ou m&eacute;dical.</p>
<p>Associ&eacute;e aux outils de synth&egrave;se articulatoire elle peut aussi &ecirc;tre utilis&eacute;e afin de fournir des retours audiovisuels dans des situations de rem&eacute;diation (par exemple pour aider un malentendant &agrave; produire la bonne articulation d&rsquo;un phon&egrave;me), d&rsquo;apprentissage (par exemple pour ma&icirc;triser la r&eacute;alisation de contrastes phon&eacute;tiques d&rsquo;une langue &eacute;trang&egrave;re) ou encore d&rsquo;am&eacute;lioration de techniques de chant dans un cadre professionnel.</p>
<h2><span style="font-size: 12pt;"><strong>Positionnement par rapport &agrave; l&rsquo;&eacute;tat de l&rsquo;art et caract&egrave;re novateur</strong></span></h2>
<p>La quasi-totalit&eacute; des travaux actuels en inversion reposent sur l&rsquo;utilisation de donn&eacute;es issues de l&rsquo;articulographie &eacute;lectro-magn&eacute;tique (EMA ElectroMagnetic Articulography) qui donne la position de quelques capteurs coll&eacute;s sur la langue et les autres articulateurs facilement accessibles. Du point de vue des techniques d&rsquo;inversion proprement dites l&rsquo;apprentissage profond est largement utilis&eacute; parce qu&rsquo;il permet d&rsquo;exploiter efficacement les corpus de donn&eacute;es EMA. &Agrave; l&rsquo;heure actuelle, l&rsquo;approche LSTM (LongShort-Term Memory) et sa variante bidirectionnelle donne les meilleurs r&eacute;sultats [<a href="https://hal.archives-ouvertes.fr/hal-03087264">3</a>].</p>
<p>Malgr&eacute; leur tr&egrave;s bonne pr&eacute;cision g&eacute;om&eacute;trique, et parce que les donn&eacute;es EMA ne peuvent couvrir que la partie du conduit vocal la plus proche de la bouche, les approches actuelles ne permettent pas de retrouver la g&eacute;om&eacute;trie compl&egrave;te du conduit vocal alors que l&rsquo;on sait par exemple que le larynx joue un r&ocirc;le d&eacute;terminant sur l&rsquo;acoustique du conduit vocal. En pratique, cela limite consid&eacute;rablement l&rsquo;int&eacute;r&ecirc;t des techniques d&rsquo;inversion puisque les r&eacute;sultats ne peuvent pas &ecirc;tre utilis&eacute;s pour reconstruire le signal de parole.</p>
<p>L&rsquo;objectif de ce projet est de lever ce verrou et l&rsquo;originalit&eacute; est de retrouver la g&eacute;om&eacute;trie compl&egrave;te du conduit vocal en utilisant les donn&eacute;es de l&rsquo;IRM dynamique que nous pouvons acqu&eacute;rir &agrave; Nancy au laboratoire IADI.</p>
<p>Cette approche ouvrira une passerelle r&eacute;ellement op&eacute;rationnelle entre les gestes articulatoires et l&rsquo;acoustique dans les deux directions (simulations num&eacute;riques physiques pour la transformation directe et inversion). Un autre aspect novateur de l&rsquo;inversion que nous proposons est le d&rsquo;identifier le r&ocirc;le de chacun des articulateurs afin de pourvoir prendre en compte une &eacute;ventuelle perturbation concernant un articulateur pr&eacute;cis.</p>
<h2><strong>Programme de travail </strong></h2>
<p>Le premier objectif est l&rsquo;inversion du signal acoustique pour retrouver l&rsquo;&eacute;volution temporelle de la coupe m&eacute;diosagittale. En effet, l&rsquo;IRM dynamique fournit des images bidimensionnelles dans le plan m&eacute;diosagittal &agrave; 50Hz de tr&egrave;s bonne qualit&eacute; et le signal de parole acquis &agrave; l&rsquo;aide d&rsquo;un microphone optique peut &ecirc;tre d&eacute;bruit&eacute; tr&egrave;s efficacement &agrave; l&rsquo;aide des algorithmes d&eacute;velopp&eacute;s dans l&rsquo;&eacute;quipe MultiSpeech (exemples disponibles sur <a href="https://artspeech.loria.fr/resources/">https://artspeech.loria.fr/resources/</a>). Nous pr&eacute;voyons d&rsquo;utiliser des corpus d&eacute;j&agrave; acquis ou en cours d&rsquo;acquisition. Ces corpus repr&eacute;sentent un volume de donn&eacute;es tr&egrave;s grand (plusieurs centaines de milliers d&rsquo;images) et il est donc n&eacute;cessaire de les pr&eacute;traiter afin d&rsquo;identifier les contours des articulateurs impliqu&eacute;s dans la production de la parole (mandibule, langue, l&egrave;vres, v&eacute;lum, larynx, &eacute;piglotte). L&rsquo;an dernier nous avons d&eacute;velopp&eacute; une approche du suivi du contour des articulateurs dans les images IRM qui donne de tr&egrave;s bons r&eacute;sultats [<a href="https://hal.archives-ouvertes.fr/hal-02962336">10</a>]. Chaque articulateur est suivi ind&eacute;pendamment des autres afin de conserver la possibilit&eacute; d&rsquo;analyser le comportement individuel d&rsquo;un articulateur, par exemple dans le cas o&ugrave; l&rsquo;un d&rsquo;eux est d&eacute;faillant. Les contours suivis automatiquement peuvent donc &ecirc;tre utilis&eacute;s pour entra&icirc;ner l&rsquo;inversion.</p>
<p>Dans un premier temps l&rsquo;objectif est de r&eacute;aliser l&rsquo;inversion en utilisant vraisemblablement l&rsquo;approche LSTM sur les donn&eacute;es d&rsquo;un petit nombre de locuteurs pour lesquels il existe des donn&eacute;es en quantit&eacute; suffisante. Cette approche devra &ecirc;tre adapt&eacute;e &agrave; la nature des donn&eacute;es et afin de pouvoir identifier la contribution de chacun des articulateurs.</p>
<p>En soi, r&eacute;ussir l&rsquo;inversion pour retrouver la forme du conduit vocal dans le plan m&eacute;diosagittal constituera d&eacute;j&agrave; un succ&egrave;s remarquable puisque les r&eacute;sultats actuels ne couvrent que tr&egrave;s partiellement le conduit vocal (quelques points sur la partie avant du conduit vocal). Il est cependant important de pouvoir transposer ce r&eacute;sultat &agrave; un sujet quelconque ce qui pose la question de l&rsquo;adaptation au locuteur qui est le second objectif.</p>
<p>&nbsp;</p>
<p>Les techniques d&rsquo;adaptation au locuteur les plus r&eacute;centes reposent sur la construction de plongements (ou &laquo;&nbsp;embeddings&nbsp;&raquo; en anglais) utilis&eacute;s tr&egrave;s largement en reconnaissance ou identification du locuteur dans l&rsquo;id&eacute;e de &laquo;&nbsp;plonger&nbsp;&raquo; un individu dans un espace continu afin de r&eacute;aliser l&rsquo;adaptation du syst&egrave;me &agrave; un nouveau locuteur [<a href="https://www.isca-speech.org/archive/Interspeech_2017/pdfs/0620.PDF">6</a>, <a href="https://ieeexplore.ieee.org/document/8461375">7</a>]. Ici, on dispose &agrave; la fois de donn&eacute;es acoustiques et de donn&eacute;es anatomiques. Dans le cadre de cette th&egrave;se l&rsquo;objectif est de construire des plongements anatomiques parce que nous souhaitons pouvoir &eacute;tudier chaque articulateur ind&eacute;pendamment des autres, ce qui n&eacute;cessite de conna&icirc;tre assez pr&eacute;cis&eacute;ment sa position et son environnement anatomique imm&eacute;diat. Cette adaptation au locuteur sur la base de quelques IRM statiques seulement, r&eacute;pond &agrave; une double contrainte : la raret&eacute; et le co&ucirc;t de l&rsquo;IRM dynamique d&rsquo;une part, l&rsquo;impossibilit&eacute; d&rsquo;utiliser l&rsquo;IRM d&rsquo;autre part, par exemple apr&egrave;s la pose d&rsquo;un implant cochl&eacute;aire dont la compatibilit&eacute; avec l&rsquo;IRM n&rsquo;est pas garantie.</p>
<p>Nous avons d&eacute;j&agrave; abord&eacute; la question de l&rsquo;adaptation anatomique &agrave; travers la construction d&rsquo;atlas dynamiques de l&rsquo;articulation des consonnes [<a href="https://hal.inria.fr/hal-03090808">8</a>] qui repose notamment sur l&rsquo;utilisation d&rsquo;une transformation assez classique en traitement d&rsquo;image m&eacute;dicale [<a href="https://doi.org/10.1109/42.796284">5</a>]. Elle a le d&eacute;faut de ne pas identifier les points de rep&egrave;re anatomiques remarquables comme tels, et la piste que nous comptons suivre consistera &agrave; s&rsquo;inspirer de plongements anatomiques r&eacute;cemment propos&eacute;s pour le traitement des images radiologiques [<a href="https://arxiv.org/abs/2012.02383">4</a>]. Dans l&rsquo;esprit, l&rsquo;id&eacute;e de ces plongements est assez proche des r&eacute;seaux LSTM (Long Short Term Memory) puisque qu&rsquo;ils associent un plongement global et un plongement local.</p>
<p><strong>&nbsp;</strong></p>
    	</div>
    </div>
        
        <div class="grand-item-offre">
    	<h4 class="list-group-item-heading">Principales activités</h4>
    	<div class="list-group-item-text text-justify">
    		<h2><strong>Environnement scientifique</strong></h2>
<p>Le ou la doctorante pourra disposer des bases de donn&eacute;es d&eacute;j&agrave; acquises dans le cadre de l&rsquo;ANR ArtSpeech (de l&rsquo;ordre de 10 minutes de parole pour 10 locuteurs) et de celles beaucoup plus vastes en cours d&rsquo;acquisition dans le cadre de l&rsquo;ANR Full3DTalkingHead (de l&rsquo;ordre de 2 heures de parole pour 2 locuteurs). Le doctorant pourra bien s&ucirc;r aussi acqu&eacute;rir des donn&eacute;es compl&eacute;mentaires &agrave; l&rsquo;aide du syst&egrave;me d&rsquo;IRM disponible au laboratoire IADI (40% du temps IRM r&eacute;serv&eacute; &agrave; la recherche).</p>
<p>L&rsquo;environnement scientifique des deux &eacute;quipes est tr&egrave;s compl&eacute;mentaire avec une tr&egrave;s forte comp&eacute;tence dans tous les domaines de l&rsquo;IRM et de l&rsquo;anatomie au sein du laboratoire IADI et de l&rsquo;apprentissage profond au sein de l&rsquo;&eacute;quipe MultiSpeech du Loria. Les deux &eacute;quipes sont proches g&eacute;ographiquement (1,5 km). Le doctorant aura un bureau dans les deux laboratoires et les moyens techniques (ordinateur, acc&egrave;s aux clusters de calcul) lui permettant de travailler dans de tr&egrave;s bonnes conditions. Une r&eacute;union de suivi aura lieu chaque semaine et chacune des deux &eacute;quipes organise un s&eacute;minaire scientifique hebdomadaire. Le doctorant aura aussi l&rsquo;occasion de participer &agrave; une ou deux &eacute;coles d&rsquo;&eacute;t&eacute; et aux conf&eacute;rences en IRM et en traitement automatique de la parole. Il sera aussi aid&eacute; pour la r&eacute;daction des articles de conf&eacute;rence ou de revue.</p>
<h2><strong>Bibliographie</strong></h2>
<ol>
<li><strong>Benjamin Elie</strong>, and Yves Laprie, Extension of the single-matrix formulation of the vocal tract: consideration of bilateral channels and connection of self-oscillating models of the vocal folds with a glottal chink. Speech Comm. 82, pp. 85-96 (2016). <a href="https://hal.archives-ouvertes.fr/hal-01199792v3">https://hal.archives-ouvertes.fr/hal-01199792v3</a></li>
<li><strong>Benjamin Elie</strong>, and Yves Laprie. Copy-synthesis of phrase-level utterances. EUSIPCO, Budapest 2016 <a href="https://hal.archives-ouvertes.fr/hal-01278462">https://hal.archives-ouvertes.fr/hal-01278462</a></li>
<li><strong>Maud Parrot</strong>, Juliette Millet, Ewan Dunbar. Independent and Automatic Evaluation of Speaker-Independent Acoustic-to-Articulatory Reconstruction. <em>Interspeech 2020 - 21st Annual Conference of the International Speech Communication Association</em>, Oct 2020, Shanghai / Virtual, China. <a href="https://hal.archives-ouvertes.fr/hal-03087264">⟨hal-03087264⟩</a></li>
<li><a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+K"><strong>Ke Yan</strong></a><strong>, </strong><a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+J">Jinzheng Cai</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+D">Dakai Jin</a> et al. Self-supervised Learning of Pixel-wise Anatomical Embeddings in Radiological Images. <a href="https://arxiv.org/abs/2012.02383">arXiv:2012.02383</a> [cs.CV], 2020</li>
<li><strong>Rueckert D, </strong>Sonoda LI, Hayes C, Hill DL, Leach MO, Hawkes DJ. Nonrigid registration using free-form deformations: application to breast MR images. IEEE Trans Med Imaging. 1999 Aug;18(8):712-21. doi: <a href="https://doi.org/10.1109/42.796284">1109/42.796284</a>.</li>
<li><strong>David Snyder, </strong>Daniel Garcia-Romero, Daniel Povey, and Sanjeev Khudanpur, &ldquo;Deep neural network embed-dings for text-independent speaker verification.,&rdquo; pp. 999&ndash;1003, Interspeech, 2017, <a href="https://www.isca-speech.org/archive/Interspeech_2017/pdfs/0620.PDF">https://www.isca-speech.org/archive/Interspeech_2017/pdfs/0620.PDF</a></li>
<li><strong>David Snyder</strong>, Daniel Garcia-Romero, Gregory Sell,Daniel Povey, and Sanjeev Khudanpur, &ldquo;X-vectors: Ro-bust dnn embeddings for speaker recognition,&rdquo; in IEEE International Conference on Acoustics, Speechand Signal Processing (ICASSP). IEEE, 2018, pp.5329&ndash;5333. <a href="https://ieeexplore.ieee.org/document/8461375">https://ieeexplore.ieee.org/document/8461375</a></li>
<li><strong>Ioannis Douros</strong>, Ajinkya Kulkarni, Chrysanthi Dourou, Yu Xie, Jacques Felblinger, Karyna Isaieva, Pierre-And&eacute; Vuissoz and Yves Laprie. Using Silence MR Image to Synthesise Dynamic MRI Vocal Tract Data of CV. <em>INTERSPEECH 2020</em>, Oct 2020, Shanga&iuml; / Virtual, China. <a href="https://hal.inria.fr/hal-03090808">⟨hal-03090808⟩</a></li>
<li><strong>Slim Ouni</strong>. Tongue Gestures Awareness and Pronunciation Training. <em>12th Annual Conference of the International Speech Communication Association - Interspeech 2011</em>, Aug 2011, Florence, Italy. <a href="https://hal.inria.fr/inria-00602418">⟨inria-00602418⟩</a></li>
<li><strong>Karyna Isaieva</strong>, Yves Laprie, Nicolas Turpault, Alexis Houssard, Jacques Felblinger &amp; Pierre-Andr&eacute; Vuissoz (2020), Automatic Tongue Delineation from MRI Images with a Convolutional Neural Network Approach, Applied Artificial Intelligence, 34:14, 1115-1123, <a href="https://hal.archives-ouvertes.fr/hal-02962336">https://hal.archives-ouvertes.fr/hal-02962336</a></li>
<li><strong>Karyna Isaieva</strong>, Y. Laprie, J. Lecl&egrave;re, Ioannis K. Douros, Jacques Felblinger &amp; Pierre-Andr&eacute; Vuissoz<em>.</em> Multimodal dataset of real-time 2D and static 3D MRI of healthy French speakers. <em>Scientific Data</em> <strong>8, </strong>258 (2021). <a href="https://doi.org/10.1038/s41597-021-01041-3">https://doi.org/10.1038/s41597-021-01041-3</a></li>
<li><strong>Vinicius Ribeiro</strong>, Karyna Isaieva, Justine Leclere, Pierre-Andr&eacute; Vuissoz, Yves Laprie. Towards the prediction of the vocal tract shape from the sequence of phonemes to be articulated. <em>iNTERSPEECH 2021</em>, Aug 2021, Brno, Czech Republic. <a href="https://hal.inria.fr/hal-03360113">⟨hal-03360113⟩</a></li>
</ol>
    	</div>
    </div>
        
        <div class="grand-item-offre">
		<h4 class="list-group-item-heading">Compétences</h4>
		<div class="list-group-item-text text-justify">
			<p>deep learning, informatique, traitement automatique de la parole, math&eacute;matiques appliqu&eacute;es</p>
<p style="margin-bottom: 0.5cm;">&nbsp;</p>
		</div>
	</div>
	    
        <div class="grand-item-offre">
    	<h4 class="list-group-item-heading">Avantages</h4>
    	<div class="list-group-item-text text-justify">
    		<ul>
<li>Restauration subventionn&eacute;e</li>
<li>Transports publics rembours&eacute;s partiellement</li>
<li>Cong&eacute;s: 7 semaines de cong&eacute;s annuels + 10 jours de RTT (base temps plein) + possibilit&eacute; d'autorisations d'absence exceptionnelle (ex : enfants malades, d&eacute;m&eacute;nagement)</li>
<li>Possibilit&eacute; de t&eacute;l&eacute;travail (apr&egrave;s 6 mois d'anciennet&eacute;) et am&eacute;nagement du temps de travail</li>
<li>&Eacute;quipements professionnels &agrave; disposition (visioconf&eacute;rence, pr&ecirc;ts de mat&eacute;riels informatiques, etc.)</li>
<li>Prestations sociales, culturelles et sportives (Association de gestion des &oelig;uvres sociales d'Inria)</li>
<li>Acc&egrave;s &agrave; la formation professionnelle</li>
<li>S&eacute;curit&eacute; sociale</li>
</ul>
    	</div>
    </div>
        
        <div class="grand-item-offre">
    	<h4 class="list-group-item-heading">Rémunération</h4>
    	<div class="list-group-item-text text-justify">
    		<p>Salary: 2051&euro; gross/month for 1st and 2<sup>nd</sup> year. 2158&euro; gross/month for 3rd year.</p>
<p>&nbsp;</p>
    	</div>
    </div>
      
                    </div>
                </div>
        
                          <div id="right" class="col-sm-5 bloc-right">	
               
                	<div class="row">
                		<div class="col-sm-12" style="padding:15px;margin-bottom :10px;">
                     	                        	                           		<a href="2023-05790.html#" class="btn btn-lg btn-danger btn-postuler-footer" style="width:100%" data-toggle="modal" data-target="#registerOffre">Postuler</a>
                        	                    			
            			</div>
            		</div>
        		    	<h4 >Partager</h4>

		<ul class="social">
		<li><a target="_blank" href="https://www.facebook.com/sharer.php?u=http://jobs.inria.fr/public/classic/fr/offres/2023-05790&title=Offre+d%27emploi+Inria&description=Doctorant F/H Inversion acoustique articulatoire de la parole à l’aide d’images IRM dynamiques" class="a-facebook btn btn-sm btn-danger"> <i class="fa fa-facebook"></i> </a></li>
		<li><a target="_blank" href="https://www.linkedin.com/shareArticle?mini=true&url=http://jobs.inria.fr/public/classic/fr/offres/2023-05790&title=Offre d'emploi Inria&summary=Doctorant F/H Inversion acoustique articulatoire de la parole à l’aide d’images IRM dynamiques" class="a-linkedin btn btn-sm btn-danger"> <i class="fa fa-linkedin"></i> </a></li>
		<li><a target="_blank" href="http://twitter.com/share?hashtags=Jobs.inria.fr,Emploi,Villers lès Nancy&text=Offre d'emploi Inria : Doctorant F/H Inversion acoustique articulatoire de la parole à l’aide d’images IRM dynamiques%0A&url=http://jobs.inria.fr/public/classic/fr/offres/2023-05790" class="a-twitter btn btn-sm btn-danger"> <i class="fa fa-twitter"></i> </a></li>
		<li><a target="_blank" href="mailto:?body=Offre d'emploi Inria :%0A Doctorant F/H Inversion acoustique articulatoire de la parole à l’aide d’images IRM dynamiques%0A%0A http://jobs.inria.fr/public/classic/fr/offres/2023-05790&subject=Offre d'emploi Inria: Doctorant F/H Inversion acoustique articulatoire de la parole à l’aide d’images IRM dynamiques" class="a-envelope btn btn-sm btn-danger"> <i class="fa fa-envelope"></i> </a></li>
	</ul>
	
        				
	<h4 >Informations générales</h4>
	<ul class="nomargin">
									<li><strong>Thème/Domaine :</strong>
											Langue, parole et audio
						<br/>										
											Calcul Scientifique
													(BAP E)
																
				</li>
							
				<li><strong>Ville :</strong>
			Villers lès Nancy
		</li>
				
				<li><strong>Centre Inria :</strong>
							<a class="a-inria" target="_blank" href="http://www.inria.fr/centre/nancy">CRI Nancy - Grand Est</a>
					</li>  
						
					<li><strong>Date de prise de fonction souhaitée :</strong>
				2023-02-14
			</li>
							<li><strong>Durée de contrat :</strong>
					2 mois
				</li>
							
				<li><strong>Date limite pour postuler :</strong>
			2023-05-15				
		</li>
			</ul>
	
        				
	<h4 >Contacts</h4>
	<ul class="nomargin">
				<li><strong>Equipe Inria :</strong>
							<a class="a-inria" href="https://www.inria.fr/equipes/MULTISPEECH" target="_blank">MULTISPEECH</a>    	
								</li>
																			<li>
			<strong>Directeur de thèse :</strong>
			<br/>
			Laprie Yves
			/
			<a class="a-inria" href="mailto:yves.laprie@loria.fr">yves.laprie@loria.fr</a>
		</li>
	    	</ul>

        				
	
        			<div class="grand-item-offre">
    					<h4 class="list-group-item-heading">A propos d&#039;Inria</h4>
    					<p class="list-group-item-text text-justify">
    		            Inria est l’institut national de recherche dédié aux sciences et technologies du numérique. Il emploie 2600 personnes. Ses 200 équipes-projets agiles, en général communes avec des partenaires académiques, impliquent plus de 3500 scientifiques pour relever les défis du numérique, souvent à l’interface d’autres disciplines. L’institut fait appel à de nombreux talents dans plus d’une quarantaine de métiers différents. 900 personnels d’appui à la recherche et à l’innovation contribuent à faire émerger et grandir des projets scientifiques ou entrepreneuriaux qui impactent le monde. Inria travaille avec de nombreuses entreprises et a accompagné la création de plus de 180 start-up. L&#039;institut s&#039;eﬀorce ainsi de répondre aux enjeux de la transformation numérique de la science, de la société et de l&#039;économie.
    					</p>
    				</div>
            			
	<h4 >Consignes pour postuler</h4>
	<div class="text-justify">
		
	</div>
				
	<p class="text-justify">
		<strong>Sécurité défense : </strong>
		<br/>
		Ce poste est susceptible d’être affecté dans une zone à régime restrictif (ZRR), telle que définie dans le décret n°2011-1425 relatif à la protection du potentiel scientifique et technique de la nation (PPST). L’autorisation d’accès à une zone est délivrée par le chef d’établissement, après avis ministériel favorable, tel que défini dans l’arrêté du 03 juillet 2012, relatif à la PPST. Un avis ministériel défavorable pour un poste affecté dans une ZRR aurait pour conséquence l’annulation du recrutement.
    </p>
             	
    <p class="text-justify">
    	<strong> Politique de recrutement :</strong>
        <br/>
		Dans le cadre de sa politique diversité, tous les postes Inria sont accessibles aux personnes en situation de handicap.
    </p>
        <p class="text-justify alert alert-warning">
		<b>Attention</b>: Les candidatures doivent être déposées en ligne sur le site Inria. Le traitement des candidatures adressées par d'autres canaux n'est pas garanti.
    </p>
    
             </div>
        </div>
    </div>
</div>

<!-- Modal Creer son compte -->
<div class="modal fade" id="registerOffre" tabindex="-1" role="dialog" aria-labelledby="myModalLabel">
    <div class="modal-dialog" role="document">
        <div class="modal-content ">
            
            <div class="modal-body">
              	<div class="row">
                  	<div class="col-md-6 pull-right">
                  		<button type="button" class="close" data-dismiss="modal" aria-label="Close"><i class="fa fa-remove"></i></button>
                  	</div>
            	</div>
            	<div class="row">
					<div class="col-md-6">
						<div class="form-group">
                        <p class="h4-inria list-group-item-text text-center">
                        Je crée mon compte
                        </p> 
                        <p class="h4 list-group-item-text text-center "> 
             			<i class="fa fa-info-circle"></i>
             			 Pour suivre votre candidature
                        </p>
            			<p class="h3 list-group-item-text text-center">
                           	<a href="https://jobs.inria.fr/public/fr/register?ref=2023-05790"  class=" btn btn-danger">
	        	        		<i class="fa fa-plus"></i> Créer un compte
           					</a>
        				</p>
             			
                        </div>
       				</div>
           
           			<div class="col-md-6"  style="border-left: 1px solid #CCC;">
           				<div class="form-group">
           			
                        <p class="h4-inria list-group-item-text text-center">
							J&#039;ai déjà un compte!
                        </p> 
            			<p class="h3 list-group-item-text text-center">
                           	<a href="https://jobs.inria.fr/public/classic/fr/offres/2023-05790/postuler"  class=" btn btn-danger">
	        	        		<i class="fa fa-sign-in"></i> Se connecter
           					</a>
        				</p>
        				</div>
       				</div>
            	</div>
        	</div>
            <div class="modal-footer" style="border: none;">
                <button type="button" class="btn btn-default" data-dismiss="modal">Annuler </button>
            </div>
            
        </div>
    </div>
</div>

<script type="text/javascript" src="../../../../library/bootstrap-select-1.12.2/dist/js/bootstrap-select.min.js"></script>
        <script type="text/javascript" src="../../../../js/moment.js"></script>
		<script type="text/javascript" src="../../../../js/bootstrap-datetimepicker.js"></script>
		<script src="../../../../js/cookiechoices.js"></script>
		<script>
				var textCookie = "En poursuivant votre navigation sur ce site vous acceptez l'utilisation des cookies pour vous proposer des contenus et services adaptés à vos centres d'intérêts.";
		var textBtnCookie = 'En savoir plus';
		var textAccept = "J'accepte";
				document.addEventListener('DOMContentLoaded', function(event){cookieChoices.showCookieConsentBar(
				textCookie, textAccept, textBtnCookie, '/public/fr/mentions-legales');
		});
		</script>

		<script type="text/javascript">

		 ScrollToTop = function() {
             var screen = $(window).scrollTop();
             if (screen > 100) {
               $('.scrollup').fadeIn();
             } else {
               $('.scrollup').fadeOut();
             }
         }
		 $('.scrollup').on('mouseover', function(){
             $(this).addClass('scrollup-mouseover');
             $(this).removeClass('scrollup-mouseout');
            });
         $('.scrollup').on('mouseout', function(){
             $(this).addClass('scrollup-mouseout');
             $(this).removeClass('scrollup-mouseover');
            });

         $('.scrollup').on('click',function () {
             $("html, body").animate({ scrollTop: 0 }, 500);

             return false;
         });

         StopAnimation = function() {
            $("html, body").bind("scroll mousedown DOMMouseScroll mousewheel keyup", function(){
                $('html, body').stop();
            });
         }

         $(window).scroll(function() {
             ScrollToTop();
             StopAnimation();
         });

		</script>


        <!-- Piwik -->
                <script type="text/javascript">
          var _paq = _paq || [];
          /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
          _paq.push(['trackPageView']);
          _paq.push(['enableLinkTracking']);
          (function() {
            var u="//piwik.inria.fr/";
            _paq.push(['setTrackerUrl', u+'piwik.php']);
            _paq.push(['setSiteId', '74']);
            var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
            g.type='text/javascript'; g.async=true; g.defer=true; g.src=u+'piwik.js'; s.parentNode.insertBefore(g,s);
          })();
        </script>
                <!-- End Piwik Code -->
    <script type="text/javascript">
    $(document).ready( function(){
        $("postulerOffre").on('click', function(){
            $('#postulerOffre').modal();
        });
    });
    </script>
    
</div>

<footer class="footer">
    <div class="col-md-12 text-center">
            <span class="text-center text-links-footer">
            <a href="../../../fr/contact.html"  target="_blank">Contact</a>&nbsp;&nbsp;|&nbsp;
            <a href="../../../fr/mentions-legales.html" target="_blank">Mentions légales</a>
                        </span>
    </div>
</footer>
<script src="https://commons.inria.fr/bootstrap/ie10-fixup/ie10-viewport-bug-workaround.js"></script><script type="text/javascript" src="../../../../library/bootstrap-select-1.12.2/dist/js/bootstrap-select.min.js"></script>
        <script type="text/javascript" src="../../../../js/moment.js"></script>
		<script type="text/javascript" src="../../../../js/bootstrap-datetimepicker.js"></script>
		<script src="../../../../js/cookiechoices.js"></script>
		<script>
				var textCookie = "En poursuivant votre navigation sur ce site vous acceptez l'utilisation des cookies pour vous proposer des contenus et services adaptés à vos centres d'intérêts.";
		var textBtnCookie = 'En savoir plus';
		var textAccept = "J'accepte";
				document.addEventListener('DOMContentLoaded', function(event){cookieChoices.showCookieConsentBar(
				textCookie, textAccept, textBtnCookie, '/public/fr/mentions-legales');
		});
		</script>

		<script type="text/javascript">

		 ScrollToTop = function() {
             var screen = $(window).scrollTop();
             if (screen > 100) {
               $('.scrollup').fadeIn();
             } else {
               $('.scrollup').fadeOut();
             }
         }
		 $('.scrollup').on('mouseover', function(){
             $(this).addClass('scrollup-mouseover');
             $(this).removeClass('scrollup-mouseout');
            });
         $('.scrollup').on('mouseout', function(){
             $(this).addClass('scrollup-mouseout');
             $(this).removeClass('scrollup-mouseover');
            });

         $('.scrollup').on('click',function () {
             $("html, body").animate({ scrollTop: 0 }, 500);

             return false;
         });

         StopAnimation = function() {
            $("html, body").bind("scroll mousedown DOMMouseScroll mousewheel keyup", function(){
                $('html, body').stop();
            });
         }

         $(window).scroll(function() {
             ScrollToTop();
             StopAnimation();
         });

		</script>


        <!-- Piwik -->
                <script type="text/javascript">
          var _paq = _paq || [];
          /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
          _paq.push(['trackPageView']);
          _paq.push(['enableLinkTracking']);
          (function() {
            var u="//piwik.inria.fr/";
            _paq.push(['setTrackerUrl', u+'piwik.php']);
            _paq.push(['setSiteId', '74']);
            var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
            g.type='text/javascript'; g.async=true; g.defer=true; g.src=u+'piwik.js'; s.parentNode.insertBefore(g,s);
          })();
        </script>
                <!-- End Piwik Code -->
    <script type="text/javascript">
    $(document).ready( function(){
        $("postulerOffre").on('click', function(){
            $('#postulerOffre').modal();
        });
    });
    </script>
</body>
</html>
